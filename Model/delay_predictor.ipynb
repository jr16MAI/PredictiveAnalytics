{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T11:19:22.298455Z",
     "start_time": "2024-05-18T11:19:22.296033Z"
    }
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.501911Z",
     "start_time": "2024-05-18T11:14:07.450138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_flights = pd.read_csv('../FlightData/flights_SFO_UA.csv')\n",
    "df_planes = pd.read_csv('../PlaneData/MainlineFleet.csv')\n",
    "df_holiday = pd.read_csv('../HolidayData/holidays_2023_2024.csv')\n",
    "df_future_flights = pd.read_csv('../FutureData/future_flights_data.csv')\n",
    "df_weather = pd.read_csv('../WeatherData/hourly_dataframe_past (1).csv')\n",
    "df_future_weather = pd.read_csv('../WeatherData/hourly_dataframe_forecast (1).csv')\n"
   ],
   "id": "fe3476cf18b2fcb9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.503930Z",
     "start_time": "2024-05-18T11:14:07.502523Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "327926f66a513c99",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.508580Z",
     "start_time": "2024-05-18T11:14:07.504569Z"
    }
   },
   "cell_type": "code",
   "source": "df_planes.info()",
   "id": "cb39b8061371b1af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1834 entries, 0 to 1833\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   PLANE_MODEL  1819 non-null   object\n",
      " 1   TAIL_NUM     1584 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 28.8+ KB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.522836Z",
     "start_time": "2024-05-18T11:14:07.510095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_express_fleet = pd.read_csv('../PlaneData/ExpressFleet.csv')\n",
    "df_mainline_fleet = pd.read_csv('../PlaneData/MainlineFleet.csv')\n",
    "\n",
    "df_planes = pd.concat([df_express_fleet, df_mainline_fleet], ignore_index=True)\n",
    "\n",
    "df_flights_plane = df_flights.merge(df_planes[['PLANE_MODEL', 'TAIL_NUM']], how='left', left_on='TAIL_NUM', right_on='TAIL_NUM')\n",
    "\n",
    "missing_plane_model = df_flights_plane[df_flights_plane['PLANE_MODEL'].isna()]['TAIL_NUM'].unique()\n",
    "print(\"Unique TAIL_NUM without a PLANE_MODEL:\", missing_plane_model, \"count:\", len(missing_plane_model))\n"
   ],
   "id": "c7ec3ee619d1a605",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique TAIL_NUM without a PLANE_MODEL: ['N13110' 'N13138' 'N14102' 'N14242' 'N17133' 'N17229' 'N18119' 'N18220'\n",
      " 'N215UA' 'N222UA' 'N228UA' 'N2331U' 'N2645U' 'N27205' 'N27421' 'N2747U'\n",
      " 'N29124' 'N29129' 'N34137' 'N37413' 'N37419' 'N37466' 'N37504' 'N38454'\n",
      " 'N38458' 'N38473' 'N39418' 'N41135' 'N417UA' 'N429UA' 'N437UA' 'N438UA'\n",
      " 'N445UA' 'N457UA' 'N467UA' 'N468UA' 'N469UA' 'N472UA' 'N476UA' 'N477UA'\n",
      " 'N48127' 'N487UA' 'N491UA' 'N57111' 'N68807' 'N69819' 'N75426' 'N76503'\n",
      " 'N76504' 'N76529' 'N76532' 'N77542' 'N779UA' 'N78506' 'N785UA' 'N87512'\n",
      " 'N14107' 'N14115' 'N14214' 'N14235' 'N19136' 'N19141' 'N21108' 'N2138U'\n",
      " 'N2142U' 'N220UA' 'N26232' 'N33203' 'N37277' 'N37422' 'N37434' 'N37506'\n",
      " 'N37510' 'N37513' 'N423UA' 'N441UA' 'N462UA' 'N475UA' 'N496UA' 'N53441'\n",
      " 'N69806' 'N69816' 'N69818' 'N73259' 'N76514' 'N77430' 'N77535' 'N776UA'\n",
      " 'N781UA' 'N787UA' 'N793UA' 'N12125' 'N14106' 'N2135U' 'N214UA' 'N27477'\n",
      " 'N36469' 'N37263' 'N39415' 'N39423' 'N41140' 'N471UA' 'N489UA' 'N76505'\n",
      " 'N76516' 'N77539' 'N775UA' 'N14118' 'N14240' 'N19117' 'N212UA' 'N2251U'\n",
      " 'N225UA' 'N226UA' 'N26226' 'N36476' 'N37273' 'N37470' 'N427UA' 'N433UA'\n",
      " 'N434UA' 'N461UA' 'N492UA' 'N58101' 'N66814' 'N68811' 'N68817' 'N73283'\n",
      " 'N75435' 'N76533' 'N14120' 'N17126' 'N2136U' 'N213UA' 'N217UA' 'N33132'\n",
      " 'N33209' 'N33264' 'N35204' 'N36444' 'N37471' 'N37508' 'N430UA' 'N444UA'\n",
      " 'N455UA' 'N64809' 'N69810' 'N75436' 'N76508' 'N76528' 'N772UA' 'N773UA'\n",
      " 'N81449' 'N12221' 'N17128' 'N216UA' 'N221UA' 'N223UA' 'N2352U' 'N36472'\n",
      " 'N37274' 'N37456' 'N422UA' 'N454UA' 'N4901U' 'N67815' 'N73275' 'N75433'\n",
      " 'N777UA' 'N780UA' 'N78438' 'N797UA' 'N12116' 'N17139' 'N24224' 'N26215'\n",
      " 'N2748U' 'N37287' 'N37420' 'N37468' 'N424UA' 'N440UA' 'N442UA' 'N480UA'\n",
      " 'N69813' 'N75429' 'N76515' 'N799UA' 'N12238' 'N13113' 'N17244' 'N18112'\n",
      " 'N210UA' 'N27239' 'N28457' 'N34222' 'N37474' 'N37507' 'N415UA' 'N449UA'\n",
      " 'N456UA' 'N47505' 'N66808' 'N73276' 'N796UA' 'N844UA' 'N87527' 'N12114'\n",
      " 'N2749U' 'N33286' 'N36247' 'N421UA' 'N459UA' 'N474UA' 'N481UA' 'N53442'\n",
      " 'N68821' 'N76269' 'N782UA' 'N78511' 'N78524' 'N79521' 'N14237' 'N209UA'\n",
      " 'N33262' 'N431UA' 'N451UA' 'N67134' 'N76517' 'N77530' 'N78448' 'N78501'\n",
      " 'N791UA' 'N87507' 'N17104' 'N17233' 'N2639U' 'N33289' 'N37298' 'N428UA'\n",
      " 'N436UA' 'N466UA' 'N470UA' 'N47414' 'N68801' 'N76523' 'N774UA' 'N219UA'\n",
      " 'N2534U' 'N446UA' 'N485UA' 'N68805' 'N769UA' 'N78509' 'N14230' 'N14231'\n",
      " 'N2333U' 'N24212' 'N36207' 'N38257' 'N432UA' 'N493UA' 'N66803' 'N77538'\n",
      " 'N206UA' 'N211UA' 'N229UA' 'N37290' 'N38424' 'N412UA' 'N425UA' 'N482UA'\n",
      " 'N77520' 'N77525' 'N24202' 'N26210' 'N27213' 'N38467' 'N413UA' 'N73291'\n",
      " 'N771UA' 'N77510' 'N79541' 'N87531' 'N11206' 'N12225' 'N27246' 'N38417'\n",
      " 'N447UA' 'N460UA' 'N75428' 'N12109' 'N12218' 'N2243U' 'N34131' 'N416UA'\n",
      " 'N479UA' 'N87513' 'N14228' 'N14249' 'N28478' 'N418UA' 'N484UA' 'N73251'\n",
      " 'N76254' 'N768UA' 'N778UA' 'N78285' 'N14250' 'N2250U' 'N39416' 'N411UA'\n",
      " 'N465UA' 'N54241' 'N76519' 'N76526' 'N794UA' 'N12216' 'N45440' 'N463UA'\n",
      " 'N67812' 'N69804' 'N73299' 'N76265' 'N77295' 'N34455' 'N448UA' 'N464UA'\n",
      " 'N75425' 'N77431' 'N795UA' 'N13248' 'N16217' 'N16234' 'N1902U' 'N26208'\n",
      " 'N2644U' 'N38446' 'N495UA' 'N57439' 'N68802' 'N19130' 'N2140U' 'N35236'\n",
      " 'N435UA' 'N478UA' 'N77537' 'N24211' 'N37253' 'N37255' 'N77258' 'N77518'\n",
      " 'N798UA' 'N227UA' 'N33292' 'N37252' 'N458UA' 'N76522' 'N786UA' 'N25201'\n",
      " 'N2737U' 'N39475' 'N486UA' 'N76502' 'N224UA' 'N473UA' 'N498UA' 'N86534'\n",
      " 'N420UA' 'N33284' 'N76288' 'N17105' 'N38459' 'N73445' 'N38443' 'N426UA'\n",
      " 'N77536' 'N784UA' 'N17245' 'N13227' 'N218UA' 'N37267' 'N2341U' 'N35271'\n",
      " 'N68452' 'N33266' 'N38451' 'N439UA' 'N37409' 'N38268' 'N414UA' 'N36272'\n",
      " 'N483UA' 'N494UA' 'N71411' 'N419UA' 'N63820' 'N2846U' 'N35260' 'N497UA'\n",
      " 'N75432' 'N783UA' 'N788UA' 'N204UA' 'N490UA' 'N78540' 'N35407' 'N13750'\n",
      " 'N30401' 'N37427' 'N403UA' 'N443UA' 'N792UA' 'N452UA' 'N404UA' 'N77296'\n",
      " 'N36447' 'N37281' 'N73256' 'N39450' 'N73270' 'N406UA' 'N68453' 'N14219'\n",
      " 'N405UA' 'N77261' 'N488UA' 'N402UA' 'N18243' 'N410UA' 'N39297' 'N401UA'\n",
      " 'N453UA' 'N408UA' 'N409UA' 'N407UA' 'N79402' 'N32404' 'N72405' 'N37408'\n",
      " 'N31412' 'N75410' 'N73406' 'N38403' 'N16709' 'N25705'] count: 446\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.526909Z",
     "start_time": "2024-05-18T11:14:07.523474Z"
    }
   },
   "cell_type": "code",
   "source": "df_flights_plane['PLANE_MODEL'].unique()",
   "id": "14837410a9bb4be0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '38M', '39M', '787-8', '787-9', '739ER', '753', '763ER',\n",
       "       '772ER', '319', '752', '77W', '787-10', '764ER', '738'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.750276Z",
     "start_time": "2024-05-18T11:14:07.527360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for origin, dest in df_flights_plane[['ORIGIN_CITY_NAME', 'DEST_CITY_NAME']].drop_duplicates().values:\n",
    "    mask = (df_flights_plane['ORIGIN_CITY_NAME'] == origin) & (df_flights_plane['DEST_CITY_NAME'] == dest)\n",
    "    \n",
    "    plane_model = df_flights_plane.loc[mask, 'PLANE_MODEL'].dropna().unique()\n",
    "    \n",
    "    if len(plane_model) > 0:\n",
    "        df_flights_plane.loc[mask & df_flights_plane['PLANE_MODEL'].isna(), 'PLANE_MODEL'] = plane_model[0]\n"
   ],
   "id": "27e4dee094305e9c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.756247Z",
     "start_time": "2024-05-18T11:14:07.750952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_tail_nums = df_flights_plane['TAIL_NUM'].nunique()\n",
    "unique_tail_nums_no_model = df_flights_plane[df_flights_plane['PLANE_MODEL'].isna()]['TAIL_NUM'].nunique()\n",
    "percentage_unique_no_model = (unique_tail_nums_no_model / unique_tail_nums) * 100\n",
    "\n",
    "total_rows = len(df_flights_plane)\n",
    "rows_no_model = df_flights_plane['PLANE_MODEL'].isna().sum()\n",
    "percentage_rows_no_model = (rows_no_model / total_rows) * 100\n",
    "\n",
    "print(f\"Percentage of unique TAIL_NUM that have no model: {percentage_unique_no_model:.2f}%\")\n",
    "print(f\"Percentage of all rows that have no model: {percentage_rows_no_model:.2f}%\")\n"
   ],
   "id": "8b12b24a4e7fd1c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of unique TAIL_NUM that have no model: 0.11%\n",
      "Percentage of all rows that have no model: 0.00%\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.763983Z",
     "start_time": "2024-05-18T11:14:07.756827Z"
    }
   },
   "cell_type": "code",
   "source": "df_flights_plane",
   "id": "61e12d49c9095450",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        ORIGIN_CITY_NAME  ORIGIN_AIRPORT_ID OP_UNIQUE_CARRIER  \\\n",
       "0      San Francisco, CA              14771                UA   \n",
       "1      San Francisco, CA              14771                UA   \n",
       "2      San Francisco, CA              14771                UA   \n",
       "3      San Francisco, CA              14771                UA   \n",
       "4      San Francisco, CA              14771                UA   \n",
       "...                  ...                ...               ...   \n",
       "50235  San Francisco, CA              14771                UA   \n",
       "50236  San Francisco, CA              14771                UA   \n",
       "50237  San Francisco, CA              14771                UA   \n",
       "50238  San Francisco, CA              14771                UA   \n",
       "50239  San Francisco, CA              14771                UA   \n",
       "\n",
       "       OP_CARRIER_FL_NUM TAIL_NUM     FL_DATE  YEAR  MONTH  DAY_OF_MONTH  \\\n",
       "0                   1665   N13110  2024-02-01  2024      2             1   \n",
       "1                    716   N13110  2024-02-01  2024      2             1   \n",
       "2                   1999   N13138  2024-02-01  2024      2             1   \n",
       "3                   2374   N14102  2024-02-01  2024      2             1   \n",
       "4                   1041   N14242  2024-02-01  2024      2             1   \n",
       "...                  ...      ...         ...   ...    ...           ...   \n",
       "50235                246   N850UA  2023-10-31  2023     10            31   \n",
       "50236               1581   N872UA  2023-10-31  2023     10            31   \n",
       "50237               1640   N881UA  2023-10-31  2023     10            31   \n",
       "50238               1107   N884UA  2023-10-31  2023     10            31   \n",
       "50239               1702   N884UA  2023-10-31  2023     10            31   \n",
       "\n",
       "       DAY_OF_WEEK         DEST_CITY_NAME  DEST_AIRPORT_ID  AIR_TIME  \\\n",
       "0                4             Boston, MA            10721     329.0   \n",
       "1                4             Boston, MA            10721     314.0   \n",
       "2                4             Denver, CO            11292     122.0   \n",
       "3                4             Boston, MA            10721     314.0   \n",
       "4                4          San Diego, CA            14679      66.0   \n",
       "...            ...                    ...              ...       ...   \n",
       "50235            2        Albuquerque, NM            10140     115.0   \n",
       "50236            2              Boise, ID            10713      70.0   \n",
       "50237            2  Dallas/Fort Worth, TX            11298     184.0   \n",
       "50238            2             Austin, TX            10423     185.0   \n",
       "50239            2  Dallas/Fort Worth, TX            11298     180.0   \n",
       "\n",
       "       DEP_TIME  DEP_DELAY  DEP_DEL15 PLANE_MODEL  \n",
       "0      23:44:00       19.0        1.0         752  \n",
       "1      08:17:00       -8.0        0.0         752  \n",
       "2      11:42:00       36.0        1.0         38M  \n",
       "3      13:30:00       15.0        1.0         752  \n",
       "4      08:27:00       -8.0        0.0         39M  \n",
       "...         ...        ...        ...         ...  \n",
       "50235  11:04:00       -6.0        0.0         319  \n",
       "50236  08:34:00      -11.0        0.0         319  \n",
       "50237  10:58:00       -8.0        0.0         319  \n",
       "50238  08:37:00       -3.0        0.0         319  \n",
       "50239  18:17:00       -8.0        0.0         319  \n",
       "\n",
       "[50240 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>PLANE_MODEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>1665</td>\n",
       "      <td>N13110</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>10721</td>\n",
       "      <td>329.0</td>\n",
       "      <td>23:44:00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>716</td>\n",
       "      <td>N13110</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>10721</td>\n",
       "      <td>314.0</td>\n",
       "      <td>08:17:00</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>1999</td>\n",
       "      <td>N13138</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>11292</td>\n",
       "      <td>122.0</td>\n",
       "      <td>11:42:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>2374</td>\n",
       "      <td>N14102</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>10721</td>\n",
       "      <td>314.0</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>1041</td>\n",
       "      <td>N14242</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>14679</td>\n",
       "      <td>66.0</td>\n",
       "      <td>08:27:00</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50235</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>246</td>\n",
       "      <td>N850UA</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>10140</td>\n",
       "      <td>115.0</td>\n",
       "      <td>11:04:00</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50236</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>1581</td>\n",
       "      <td>N872UA</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>Boise, ID</td>\n",
       "      <td>10713</td>\n",
       "      <td>70.0</td>\n",
       "      <td>08:34:00</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50237</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>1640</td>\n",
       "      <td>N881UA</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>11298</td>\n",
       "      <td>184.0</td>\n",
       "      <td>10:58:00</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50238</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>1107</td>\n",
       "      <td>N884UA</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>10423</td>\n",
       "      <td>185.0</td>\n",
       "      <td>08:37:00</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50239</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>1702</td>\n",
       "      <td>N884UA</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>11298</td>\n",
       "      <td>180.0</td>\n",
       "      <td>18:17:00</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50240 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.770180Z",
     "start_time": "2024-05-18T11:14:07.764620Z"
    }
   },
   "cell_type": "code",
   "source": "df_flights_plane = df_flights_plane.dropna(subset=['PLANE_MODEL'])",
   "id": "239d652a9fc1ba04",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.919602Z",
     "start_time": "2024-05-18T11:14:07.770677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flights_plane_csv_path = '/Users/judith.rethmann/Documents/MBS/PredictiveAnalytics/Model/flights_plane.csv'\n",
    "df_flights_plane.to_csv(flights_plane_csv_path, index=False)\n",
    "print(f\"Combined CSV file saved as '{flights_plane_csv_path}'\")\n"
   ],
   "id": "9a1a9416401b59c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV file saved as '/Users/judith.rethmann/Documents/MBS/PredictiveAnalytics/Model/flights_plane.csv'\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.929783Z",
     "start_time": "2024-05-18T11:14:07.920270Z"
    }
   },
   "cell_type": "code",
   "source": "df_flights_plane.info()",
   "id": "99485b050ce8957c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50239 entries, 0 to 50239\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ORIGIN_CITY_NAME   50239 non-null  object \n",
      " 1   ORIGIN_AIRPORT_ID  50239 non-null  int64  \n",
      " 2   OP_UNIQUE_CARRIER  50239 non-null  object \n",
      " 3   OP_CARRIER_FL_NUM  50239 non-null  int64  \n",
      " 4   TAIL_NUM           50239 non-null  object \n",
      " 5   FL_DATE            50239 non-null  object \n",
      " 6   YEAR               50239 non-null  int64  \n",
      " 7   MONTH              50239 non-null  int64  \n",
      " 8   DAY_OF_MONTH       50239 non-null  int64  \n",
      " 9   DAY_OF_WEEK        50239 non-null  int64  \n",
      " 10  DEST_CITY_NAME     50239 non-null  object \n",
      " 11  DEST_AIRPORT_ID    50239 non-null  int64  \n",
      " 12  AIR_TIME           50239 non-null  float64\n",
      " 13  DEP_TIME           50239 non-null  object \n",
      " 14  DEP_DELAY          50239 non-null  float64\n",
      " 15  DEP_DEL15          50239 non-null  float64\n",
      " 16  PLANE_MODEL        50239 non-null  object \n",
      "dtypes: float64(3), int64(7), object(7)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.935275Z",
     "start_time": "2024-05-18T11:14:07.930349Z"
    }
   },
   "cell_type": "code",
   "source": "df_flights_plane.head()",
   "id": "2666b64395751716",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    ORIGIN_CITY_NAME  ORIGIN_AIRPORT_ID OP_UNIQUE_CARRIER  OP_CARRIER_FL_NUM  \\\n",
       "0  San Francisco, CA              14771                UA               1665   \n",
       "1  San Francisco, CA              14771                UA                716   \n",
       "2  San Francisco, CA              14771                UA               1999   \n",
       "3  San Francisco, CA              14771                UA               2374   \n",
       "4  San Francisco, CA              14771                UA               1041   \n",
       "\n",
       "  TAIL_NUM     FL_DATE  YEAR  MONTH  DAY_OF_MONTH  DAY_OF_WEEK DEST_CITY_NAME  \\\n",
       "0   N13110  2024-02-01  2024      2             1            4     Boston, MA   \n",
       "1   N13110  2024-02-01  2024      2             1            4     Boston, MA   \n",
       "2   N13138  2024-02-01  2024      2             1            4     Denver, CO   \n",
       "3   N14102  2024-02-01  2024      2             1            4     Boston, MA   \n",
       "4   N14242  2024-02-01  2024      2             1            4  San Diego, CA   \n",
       "\n",
       "   DEST_AIRPORT_ID  AIR_TIME  DEP_TIME  DEP_DELAY  DEP_DEL15 PLANE_MODEL  \n",
       "0            10721     329.0  23:44:00       19.0        1.0         752  \n",
       "1            10721     314.0  08:17:00       -8.0        0.0         752  \n",
       "2            11292     122.0  11:42:00       36.0        1.0         38M  \n",
       "3            10721     314.0  13:30:00       15.0        1.0         752  \n",
       "4            14679      66.0  08:27:00       -8.0        0.0         39M  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>PLANE_MODEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>1665</td>\n",
       "      <td>N13110</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>10721</td>\n",
       "      <td>329.0</td>\n",
       "      <td>23:44:00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>716</td>\n",
       "      <td>N13110</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>10721</td>\n",
       "      <td>314.0</td>\n",
       "      <td>08:17:00</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>1999</td>\n",
       "      <td>N13138</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>11292</td>\n",
       "      <td>122.0</td>\n",
       "      <td>11:42:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>2374</td>\n",
       "      <td>N14102</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>10721</td>\n",
       "      <td>314.0</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14771</td>\n",
       "      <td>UA</td>\n",
       "      <td>1041</td>\n",
       "      <td>N14242</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>14679</td>\n",
       "      <td>66.0</td>\n",
       "      <td>08:27:00</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.940262Z",
     "start_time": "2024-05-18T11:14:07.937505Z"
    }
   },
   "cell_type": "code",
   "source": "df_future_flights.info()",
   "id": "2aa60c1793b3e44d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 203 entries, 0 to 202\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   clean_date         203 non-null    object\n",
      " 1   carrier            203 non-null    object\n",
      " 2   flightnumber       203 non-null    int64 \n",
      " 3   airport_name       203 non-null    object\n",
      " 4   airport_city_name  203 non-null    object\n",
      " 5   airport_IATA       203 non-null    object\n",
      " 6   aircraft_name      203 non-null    object\n",
      " 7   aircraft_IATA      203 non-null    object\n",
      " 8   departure_time     203 non-null    object\n",
      " 9   arrival_time       203 non-null    object\n",
      " 10  elapsed_time       203 non-null    int64 \n",
      " 11  codeshare_info     186 non-null    object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 19.2+ KB\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.944374Z",
     "start_time": "2024-05-18T11:14:07.940769Z"
    }
   },
   "cell_type": "code",
   "source": "df_future_flights.head()",
   "id": "73b93fad5e5179c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   clean_date carrier  flightnumber                 airport_name  \\\n",
       "0  2024-05-31      UA           512  George Bush Intcntl Houston   \n",
       "1  2024-05-31      UA           189   Ninoy Aquino International   \n",
       "2  2024-05-31      UA          1139  Chicago Ohare International   \n",
       "3  2024-05-31      UA           274  George Bush Intcntl Houston   \n",
       "4  2024-05-31      UA          1003         Denver International   \n",
       "\n",
       "  airport_city_name airport_IATA              aircraft_name aircraft_IATA  \\\n",
       "0           Houston          IAH  Boeing 737MAX 9 Passenger           7M9   \n",
       "1            Manila          MNL           Boeing 777-300ER           77W   \n",
       "2           Chicago          ORD   Boeing 737-900 Passenger           739   \n",
       "3           Houston          IAH  Boeing 737MAX 9 Passenger           7M9   \n",
       "4            Denver          DEN   Boeing 757-300 Passenger           753   \n",
       "\n",
       "  departure_time arrival_time  elapsed_time             codeshare_info  \n",
       "0          00:30     06:26:00           236           NZ 9190 /VA 8082  \n",
       "1          00:45     05:55:00           850                        NaN  \n",
       "2          01:10     07:30:00           260           AC 3088 /NZ 9308  \n",
       "3          05:00     11:03:00           243           NZ 9198 /VA 8084  \n",
       "4          05:00     08:37:00           157  AC 4046 /NZ 9057 /VA 8335  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_date</th>\n",
       "      <th>carrier</th>\n",
       "      <th>flightnumber</th>\n",
       "      <th>airport_name</th>\n",
       "      <th>airport_city_name</th>\n",
       "      <th>airport_IATA</th>\n",
       "      <th>aircraft_name</th>\n",
       "      <th>aircraft_IATA</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>codeshare_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>UA</td>\n",
       "      <td>512</td>\n",
       "      <td>George Bush Intcntl Houston</td>\n",
       "      <td>Houston</td>\n",
       "      <td>IAH</td>\n",
       "      <td>Boeing 737MAX 9 Passenger</td>\n",
       "      <td>7M9</td>\n",
       "      <td>00:30</td>\n",
       "      <td>06:26:00</td>\n",
       "      <td>236</td>\n",
       "      <td>NZ 9190 /VA 8082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>UA</td>\n",
       "      <td>189</td>\n",
       "      <td>Ninoy Aquino International</td>\n",
       "      <td>Manila</td>\n",
       "      <td>MNL</td>\n",
       "      <td>Boeing 777-300ER</td>\n",
       "      <td>77W</td>\n",
       "      <td>00:45</td>\n",
       "      <td>05:55:00</td>\n",
       "      <td>850</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>UA</td>\n",
       "      <td>1139</td>\n",
       "      <td>Chicago Ohare International</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Boeing 737-900 Passenger</td>\n",
       "      <td>739</td>\n",
       "      <td>01:10</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>260</td>\n",
       "      <td>AC 3088 /NZ 9308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>UA</td>\n",
       "      <td>274</td>\n",
       "      <td>George Bush Intcntl Houston</td>\n",
       "      <td>Houston</td>\n",
       "      <td>IAH</td>\n",
       "      <td>Boeing 737MAX 9 Passenger</td>\n",
       "      <td>7M9</td>\n",
       "      <td>05:00</td>\n",
       "      <td>11:03:00</td>\n",
       "      <td>243</td>\n",
       "      <td>NZ 9198 /VA 8084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>UA</td>\n",
       "      <td>1003</td>\n",
       "      <td>Denver International</td>\n",
       "      <td>Denver</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Boeing 757-300 Passenger</td>\n",
       "      <td>753</td>\n",
       "      <td>05:00</td>\n",
       "      <td>08:37:00</td>\n",
       "      <td>157</td>\n",
       "      <td>AC 4046 /NZ 9057 /VA 8335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.971444Z",
     "start_time": "2024-05-18T11:14:07.944949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_flights_plane['DEST_CITY_NAME'] = df_flights_plane['DEST_CITY_NAME'].str.replace(r',.*', '', regex=True)\n",
    "df_flights_plane['ORIGIN_CITY_NAME'] = df_flights_plane['ORIGIN_CITY_NAME'].str.replace(r',.*', '', regex=True)"
   ],
   "id": "a27c84c26e4f50a1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/g2lg_kq17xgb1zndw9jlbyn80000gn/T/ipykernel_45663/506844661.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_flights_plane['DEST_CITY_NAME'] = df_flights_plane['DEST_CITY_NAME'].str.replace(r',.*', '', regex=True)\n",
      "/var/folders/hx/g2lg_kq17xgb1zndw9jlbyn80000gn/T/ipykernel_45663/506844661.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_flights_plane['ORIGIN_CITY_NAME'] = df_flights_plane['ORIGIN_CITY_NAME'].str.replace(r',.*', '', regex=True)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.974119Z",
     "start_time": "2024-05-18T11:14:07.971992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "df_future_flights = df_future_flights.drop(columns=[\n",
    "    'flightnumber', \n",
    "    'airport_name', \n",
    "    'airport_IATA', \n",
    "    'aircraft_name', \n",
    "    'arrival_time', \n",
    "    'codeshare_info',\n",
    "    'carrier'\n",
    "])\n",
    "\n",
    "df_future_flights = df_future_flights.rename(columns={\n",
    "    'clean_date': 'FL_DATE',\n",
    "    'airport_city_name': 'DEST_CITY_NAME',\n",
    "    'aircraft_IATA': 'PLANE_MODEL',\n",
    "    'departure_time': 'DEP_TIME',\n",
    "    'elapsed_time': 'AIR_TIME'\n",
    "})\n"
   ],
   "id": "864a1477451d2448",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.978155Z",
     "start_time": "2024-05-18T11:14:07.974658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns_to_drop = [\n",
    "    'ORIGIN_AIRPORT_ID', \n",
    "    'OP_UNIQUE_CARRIER', \n",
    "    'OP_CARRIER_FL_NUM', \n",
    "    'TAIL_NUM', \n",
    "    'YEAR', \n",
    "    'MONTH', \n",
    "    'DAY_OF_MONTH', \n",
    "    'DEST_AIRPORT_ID', \n",
    "    'DEP_DELAY',\n",
    "    'ORIGIN_CITY_NAME'\n",
    "]\n",
    "\n",
    "df_flights_plane = df_flights_plane.drop(columns=columns_to_drop)"
   ],
   "id": "ccd53a32dea8b20e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.985518Z",
     "start_time": "2024-05-18T11:14:07.978674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_future_flights['FL_DATE'] = pd.to_datetime(df_future_flights['FL_DATE'])\n",
    "df_future_flights['DAY_OF_WEEK'] = df_future_flights['FL_DATE'].dt.dayofweek\n",
    "df_flights_plane['FL_DATE'] = pd.to_datetime(df_flights_plane['FL_DATE'])\n",
    "df_flights_plane['DAY_OF_WEEK'] = df_flights_plane['FL_DATE'].dt.dayofweek"
   ],
   "id": "a3e88bd268312d2d",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.989831Z",
     "start_time": "2024-05-18T11:14:07.986056Z"
    }
   },
   "cell_type": "code",
   "source": "df_future_flights",
   "id": "c2cc0d6ab98cd79b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       FL_DATE DEST_CITY_NAME PLANE_MODEL DEP_TIME  AIR_TIME  DAY_OF_WEEK\n",
       "0   2024-05-31        Houston         7M9    00:30       236            4\n",
       "1   2024-05-31         Manila         77W    00:45       850            4\n",
       "2   2024-05-31        Chicago         739    01:10       260            4\n",
       "3   2024-05-31        Houston         7M9    05:00       243            4\n",
       "4   2024-05-31         Denver         753    05:00       157            4\n",
       "..         ...            ...         ...      ...       ...          ...\n",
       "198 2024-05-31         Taipei         777    23:45       800            4\n",
       "199 2024-05-31      Hong Kong         77W    23:50       850            4\n",
       "200 2024-05-31          Seoul         777    23:55       745            4\n",
       "201 2024-05-31        Houston         777    23:59       235            4\n",
       "202 2024-05-31   Philadelphia         7M8    23:59       334            4\n",
       "\n",
       "[203 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>PLANE_MODEL</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>Houston</td>\n",
       "      <td>7M9</td>\n",
       "      <td>00:30</td>\n",
       "      <td>236</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>Manila</td>\n",
       "      <td>77W</td>\n",
       "      <td>00:45</td>\n",
       "      <td>850</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>739</td>\n",
       "      <td>01:10</td>\n",
       "      <td>260</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>Houston</td>\n",
       "      <td>7M9</td>\n",
       "      <td>05:00</td>\n",
       "      <td>243</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>Denver</td>\n",
       "      <td>753</td>\n",
       "      <td>05:00</td>\n",
       "      <td>157</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>Taipei</td>\n",
       "      <td>777</td>\n",
       "      <td>23:45</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>77W</td>\n",
       "      <td>23:50</td>\n",
       "      <td>850</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>777</td>\n",
       "      <td>23:55</td>\n",
       "      <td>745</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>Houston</td>\n",
       "      <td>777</td>\n",
       "      <td>23:59</td>\n",
       "      <td>235</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>7M8</td>\n",
       "      <td>23:59</td>\n",
       "      <td>334</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:07.999732Z",
     "start_time": "2024-05-18T11:14:07.990391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns_order_future = ['FL_DATE', 'DAY_OF_WEEK', 'DEST_CITY_NAME', 'AIR_TIME', 'DEP_TIME', 'PLANE_MODEL']\n",
    "df_future_flights = df_future_flights[columns_order_future]\n",
    "columns_order_past = ['FL_DATE', 'DAY_OF_WEEK', 'DEST_CITY_NAME', 'AIR_TIME', 'DEP_TIME', 'PLANE_MODEL', 'DEP_DEL15']\n",
    "df_flights_plane = df_flights_plane[columns_order_past]\n",
    "\n",
    "df_future_flights['AIR_TIME'] = df_future_flights['AIR_TIME'].astype('float64')\n",
    "df_flights_plane['DEP_DEL15'] = df_flights_plane['DEP_DEL15'].astype('int')\n",
    "\n",
    "print(df_future_flights.info())\n",
    "print(df_flights_plane.info())"
   ],
   "id": "3a6d60c0f415e7e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 203 entries, 0 to 202\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   FL_DATE         203 non-null    datetime64[ns]\n",
      " 1   DAY_OF_WEEK     203 non-null    int32         \n",
      " 2   DEST_CITY_NAME  203 non-null    object        \n",
      " 3   AIR_TIME        203 non-null    float64       \n",
      " 4   DEP_TIME        203 non-null    object        \n",
      " 5   PLANE_MODEL     203 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(1), int32(1), object(3)\n",
      "memory usage: 8.9+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50239 entries, 0 to 50239\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   FL_DATE         50239 non-null  datetime64[ns]\n",
      " 1   DAY_OF_WEEK     50239 non-null  int32         \n",
      " 2   DEST_CITY_NAME  50239 non-null  object        \n",
      " 3   AIR_TIME        50239 non-null  float64       \n",
      " 4   DEP_TIME        50239 non-null  object        \n",
      " 5   PLANE_MODEL     50239 non-null  object        \n",
      " 6   DEP_DEL15       50239 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int32(1), int64(1), object(3)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.003328Z",
     "start_time": "2024-05-18T11:14:08.000342Z"
    }
   },
   "cell_type": "code",
   "source": "df_weather.info()",
   "id": "33d6c1314907731a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11304 entries, 0 to 11303\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   date                  11304 non-null  object \n",
      " 1   temperature_2m        11304 non-null  float64\n",
      " 2   relative_humidity_2m  11304 non-null  float64\n",
      " 3   precipitation         11304 non-null  float64\n",
      " 4   pressure_msl          11304 non-null  float64\n",
      " 5   cloud_cover           11304 non-null  float64\n",
      " 6   wind_speed_10m        11304 non-null  float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 618.3+ KB\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.006365Z",
     "start_time": "2024-05-18T11:14:08.003860Z"
    }
   },
   "cell_type": "code",
   "source": "df_future_weather.info()",
   "id": "589bddbaf14df815",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 379 entries, 0 to 378\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   date                  379 non-null    object \n",
      " 1   temperature_2m        379 non-null    float64\n",
      " 2   relative_humidity_2m  379 non-null    int64  \n",
      " 3   precipitation         379 non-null    int64  \n",
      " 4   pressure_msl          379 non-null    float64\n",
      " 5   cloud_cover           379 non-null    float64\n",
      " 6   wind_speed_10m        379 non-null    int64  \n",
      "dtypes: float64(3), int64(3), object(1)\n",
      "memory usage: 20.9+ KB\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.010652Z",
     "start_time": "2024-05-18T11:14:08.006998Z"
    }
   },
   "cell_type": "code",
   "source": "df_weather.head()",
   "id": "9a192e7fed90668f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        date  temperature_2m  relative_humidity_2m  \\\n",
       "0  2023-02-01 00:00:00+00:00         12.3315             37.520824   \n",
       "1  2023-02-01 01:00:00+00:00         10.3315             59.707893   \n",
       "2  2023-02-01 02:00:00+00:00          8.4315             60.962593   \n",
       "3  2023-02-01 03:00:00+00:00          7.7815             68.920550   \n",
       "4  2023-02-01 04:00:00+00:00          7.2315             77.622500   \n",
       "\n",
       "   precipitation  pressure_msl  cloud_cover  wind_speed_10m  \n",
       "0            0.0        1021.1    1018.0508        6.300000  \n",
       "1            0.0        1021.1    1018.0290       10.500000  \n",
       "2            0.0        1021.6    1018.5068       17.700000  \n",
       "3            0.0        1021.7    1018.5995       29.400002  \n",
       "4            0.0        1022.0    1018.8925       29.100000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>pressure_msl</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-01 00:00:00+00:00</td>\n",
       "      <td>12.3315</td>\n",
       "      <td>37.520824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.1</td>\n",
       "      <td>1018.0508</td>\n",
       "      <td>6.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-01 01:00:00+00:00</td>\n",
       "      <td>10.3315</td>\n",
       "      <td>59.707893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.1</td>\n",
       "      <td>1018.0290</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-01 02:00:00+00:00</td>\n",
       "      <td>8.4315</td>\n",
       "      <td>60.962593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.6</td>\n",
       "      <td>1018.5068</td>\n",
       "      <td>17.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-01 03:00:00+00:00</td>\n",
       "      <td>7.7815</td>\n",
       "      <td>68.920550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.7</td>\n",
       "      <td>1018.5995</td>\n",
       "      <td>29.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-01 04:00:00+00:00</td>\n",
       "      <td>7.2315</td>\n",
       "      <td>77.622500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1018.8925</td>\n",
       "      <td>29.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.014566Z",
     "start_time": "2024-05-18T11:14:08.011172Z"
    }
   },
   "cell_type": "code",
   "source": "df_future_weather.head()\n",
   "id": "6fa8d32c23001bd6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        date  temperature_2m  relative_humidity_2m  \\\n",
       "0  2024-05-18 00:00:00+00:00       17.507000                    73   \n",
       "1  2024-05-18 01:00:00+00:00       15.907000                    75   \n",
       "2  2024-05-18 02:00:00+00:00       15.207001                    77   \n",
       "3  2024-05-18 03:00:00+00:00       13.707001                    79   \n",
       "4  2024-05-18 04:00:00+00:00       12.707001                    79   \n",
       "\n",
       "   precipitation  pressure_msl  cloud_cover  wind_speed_10m  \n",
       "0              0        1012.5   1009.52990               5  \n",
       "1              0        1012.3   1009.31440             100  \n",
       "2              0        1012.1   1009.10767             100  \n",
       "3              0        1012.1   1009.09180             100  \n",
       "4              0        1012.5   1009.48020               3  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>pressure_msl</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-18 00:00:00+00:00</td>\n",
       "      <td>17.507000</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1012.5</td>\n",
       "      <td>1009.52990</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-18 01:00:00+00:00</td>\n",
       "      <td>15.907000</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1012.3</td>\n",
       "      <td>1009.31440</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-18 02:00:00+00:00</td>\n",
       "      <td>15.207001</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>1012.1</td>\n",
       "      <td>1009.10767</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-18 03:00:00+00:00</td>\n",
       "      <td>13.707001</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1012.1</td>\n",
       "      <td>1009.09180</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-18 04:00:00+00:00</td>\n",
       "      <td>12.707001</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1012.5</td>\n",
       "      <td>1009.48020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.020915Z",
     "start_time": "2024-05-18T11:14:08.015206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_to_convert = ['relative_humidity_2m', 'precipitation', 'wind_speed_10m']\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    df_weather[col] = df_weather[col].astype(float).round().astype(int)\n",
    "\n",
    "print(df_future_weather.info())\n",
    "print(df_weather.info())"
   ],
   "id": "8e6c2b46d3d99896",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 379 entries, 0 to 378\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   date                  379 non-null    object \n",
      " 1   temperature_2m        379 non-null    float64\n",
      " 2   relative_humidity_2m  379 non-null    int64  \n",
      " 3   precipitation         379 non-null    int64  \n",
      " 4   pressure_msl          379 non-null    float64\n",
      " 5   cloud_cover           379 non-null    float64\n",
      " 6   wind_speed_10m        379 non-null    int64  \n",
      "dtypes: float64(3), int64(3), object(1)\n",
      "memory usage: 20.9+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11304 entries, 0 to 11303\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   date                  11304 non-null  object \n",
      " 1   temperature_2m        11304 non-null  float64\n",
      " 2   relative_humidity_2m  11304 non-null  int64  \n",
      " 3   precipitation         11304 non-null  int64  \n",
      " 4   pressure_msl          11304 non-null  float64\n",
      " 5   cloud_cover           11304 non-null  float64\n",
      " 6   wind_speed_10m        11304 non-null  int64  \n",
      "dtypes: float64(3), int64(3), object(1)\n",
      "memory usage: 618.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.033885Z",
     "start_time": "2024-05-18T11:14:08.021603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_date_time(df, date_col):\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df['time'] = df[date_col].dt.time\n",
    "    df[date_col] = df[date_col].dt.date\n",
    "    return df\n",
    "\n",
    "df_weather = split_date_time(df_weather, 'date')\n",
    "df_future_weather = split_date_time(df_future_weather, 'date')"
   ],
   "id": "ab05604b6fceb36d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.038844Z",
     "start_time": "2024-05-18T11:14:08.034394Z"
    }
   },
   "cell_type": "code",
   "source": "df_future_weather",
   "id": "1c07370883c58ab8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           date  temperature_2m  relative_humidity_2m  precipitation  \\\n",
       "0    2024-05-18       17.507000                    73              0   \n",
       "1    2024-05-18       15.907000                    75              0   \n",
       "2    2024-05-18       15.207001                    77              0   \n",
       "3    2024-05-18       13.707001                    79              0   \n",
       "4    2024-05-18       12.707001                    79              0   \n",
       "..          ...             ...                   ...            ...   \n",
       "374  2024-06-02       12.570499                    89              0   \n",
       "375  2024-06-02       13.020499                    87              0   \n",
       "376  2024-06-02       14.120500                    82              0   \n",
       "377  2024-06-02       15.520499                    76              0   \n",
       "378  2024-06-02       16.520500                    72              0   \n",
       "\n",
       "     pressure_msl  cloud_cover  wind_speed_10m      time  \n",
       "0          1012.5   1009.52990               5  00:00:00  \n",
       "1          1012.3   1009.31440             100  01:00:00  \n",
       "2          1012.1   1009.10767             100  02:00:00  \n",
       "3          1012.1   1009.09180             100  03:00:00  \n",
       "4          1012.5   1009.48020               3  04:00:00  \n",
       "..            ...          ...             ...       ...  \n",
       "374        1012.8   1009.77810              97  14:00:00  \n",
       "375        1013.1   1010.08185             100  15:00:00  \n",
       "376        1013.2   1010.19300             100  16:00:00  \n",
       "377        1013.3   1010.30740             100  17:00:00  \n",
       "378        1013.3   1010.31780             100  18:00:00  \n",
       "\n",
       "[379 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>pressure_msl</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>17.507000</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1012.5</td>\n",
       "      <td>1009.52990</td>\n",
       "      <td>5</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>15.907000</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1012.3</td>\n",
       "      <td>1009.31440</td>\n",
       "      <td>100</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>15.207001</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>1012.1</td>\n",
       "      <td>1009.10767</td>\n",
       "      <td>100</td>\n",
       "      <td>02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>13.707001</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1012.1</td>\n",
       "      <td>1009.09180</td>\n",
       "      <td>100</td>\n",
       "      <td>03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>12.707001</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1012.5</td>\n",
       "      <td>1009.48020</td>\n",
       "      <td>3</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2024-06-02</td>\n",
       "      <td>12.570499</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>1009.77810</td>\n",
       "      <td>97</td>\n",
       "      <td>14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2024-06-02</td>\n",
       "      <td>13.020499</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1013.1</td>\n",
       "      <td>1010.08185</td>\n",
       "      <td>100</td>\n",
       "      <td>15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2024-06-02</td>\n",
       "      <td>14.120500</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1013.2</td>\n",
       "      <td>1010.19300</td>\n",
       "      <td>100</td>\n",
       "      <td>16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2024-06-02</td>\n",
       "      <td>15.520499</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1013.3</td>\n",
       "      <td>1010.30740</td>\n",
       "      <td>100</td>\n",
       "      <td>17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2024-06-02</td>\n",
       "      <td>16.520500</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1013.3</td>\n",
       "      <td>1010.31780</td>\n",
       "      <td>100</td>\n",
       "      <td>18:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.117773Z",
     "start_time": "2024-05-18T11:14:08.039293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_hour(df, time_col):\n",
    "    df[time_col] = df[time_col].astype(str)\n",
    "    df['hour'] = df[time_col].str.extract(r'(\\d{2})').astype(int)\n",
    "    return df\n",
    "\n",
    "df_flights_plane['DEP_TIME'] = df_flights_plane['DEP_TIME'].astype(str)\n",
    "df_future_flights['DEP_TIME'] = df_future_flights['DEP_TIME'].astype(str)\n",
    "df_weather['time'] = df_weather['time'].astype(str)\n",
    "df_future_weather['time'] = df_future_weather['time'].astype(str)\n",
    "\n",
    "df_flights_plane = extract_hour(df_flights_plane, 'DEP_TIME')\n",
    "df_future_flights = extract_hour(df_future_flights, 'DEP_TIME')\n",
    "df_weather = extract_hour(df_weather, 'time')\n",
    "df_future_weather = extract_hour(df_future_weather, 'time')\n",
    "\n",
    "df_flights_plane['FL_DATE'] = pd.to_datetime(df_flights_plane['FL_DATE'])\n",
    "df_future_flights['FL_DATE'] = pd.to_datetime(df_future_flights['FL_DATE'])\n",
    "df_weather['date'] = pd.to_datetime(df_weather['date'])\n",
    "df_future_weather['date'] = pd.to_datetime(df_future_weather['date'])\n",
    "\n",
    "df_merged_weather = pd.merge(df_flights_plane, df_weather, left_on=['FL_DATE', 'hour'], right_on=['date', 'hour'], how='left')\n",
    "df_merged_future_weather = pd.merge(df_future_flights, df_future_weather, left_on=['FL_DATE', 'hour'], right_on=['date', 'hour'], how='left')\n",
    "\n",
    "df_merged_weather = df_merged_weather.drop(columns=['hour', 'date', 'time'])\n",
    "df_merged_future_weather = df_merged_future_weather.drop(columns=['hour', 'date', 'time'])\n",
    "\n",
    "print(df_merged_weather)\n",
    "print(df_merged_future_weather)\n"
   ],
   "id": "d2a847b8cc7a6929",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         FL_DATE  DAY_OF_WEEK     DEST_CITY_NAME  AIR_TIME  DEP_TIME  \\\n",
      "0     2024-02-01            3             Boston     329.0  23:44:00   \n",
      "1     2024-02-01            3             Boston     314.0  08:17:00   \n",
      "2     2024-02-01            3             Denver     122.0  11:42:00   \n",
      "3     2024-02-01            3             Boston     314.0  13:30:00   \n",
      "4     2024-02-01            3          San Diego      66.0  08:27:00   \n",
      "...          ...          ...                ...       ...       ...   \n",
      "50234 2023-10-31            1        Albuquerque     115.0  11:04:00   \n",
      "50235 2023-10-31            1              Boise      70.0  08:34:00   \n",
      "50236 2023-10-31            1  Dallas/Fort Worth     184.0  10:58:00   \n",
      "50237 2023-10-31            1             Austin     185.0  08:37:00   \n",
      "50238 2023-10-31            1  Dallas/Fort Worth     180.0  18:17:00   \n",
      "\n",
      "      PLANE_MODEL  DEP_DEL15  temperature_2m  relative_humidity_2m  \\\n",
      "0             752          1         12.6315                    78   \n",
      "1             752          0         11.1815                    95   \n",
      "2             38M          1         10.8815                    94   \n",
      "3             752          1         11.4815                    90   \n",
      "4             39M          0         11.1815                    95   \n",
      "...           ...        ...             ...                   ...   \n",
      "50234         319          0          9.4815                    88   \n",
      "50235         319          0         14.6315                    51   \n",
      "50236         319          0         12.1315                    72   \n",
      "50237         319          0         14.6315                    51   \n",
      "50238         319          0         15.8815                    57   \n",
      "\n",
      "       precipitation  pressure_msl  cloud_cover  wind_speed_10m  \n",
      "0                  0        1005.0   1002.00195              33  \n",
      "1                  0        1002.8    999.79320              89  \n",
      "2                  2        1003.6   1000.58760             100  \n",
      "3                  0        1003.0    999.99570             100  \n",
      "4                  0        1002.8    999.79320              89  \n",
      "...              ...           ...          ...             ...  \n",
      "50234              0        1020.1   1017.02280              10  \n",
      "50235              0        1020.4   1017.37710               5  \n",
      "50236              0        1020.3   1017.25085               8  \n",
      "50237              0        1020.4   1017.37710               5  \n",
      "50238              0        1021.4   1018.38720              31  \n",
      "\n",
      "[50239 rows x 13 columns]\n",
      "       FL_DATE  DAY_OF_WEEK DEST_CITY_NAME  AIR_TIME DEP_TIME PLANE_MODEL  \\\n",
      "0   2024-05-31            4        Houston     236.0    00:30         7M9   \n",
      "1   2024-05-31            4         Manila     850.0    00:45         77W   \n",
      "2   2024-05-31            4        Chicago     260.0    01:10         739   \n",
      "3   2024-05-31            4        Houston     243.0    05:00         7M9   \n",
      "4   2024-05-31            4         Denver     157.0    05:00         753   \n",
      "..         ...          ...            ...       ...      ...         ...   \n",
      "198 2024-05-31            4         Taipei     800.0    23:45         777   \n",
      "199 2024-05-31            4      Hong Kong     850.0    23:50         77W   \n",
      "200 2024-05-31            4          Seoul     745.0    23:55         777   \n",
      "201 2024-05-31            4        Houston     235.0    23:59         777   \n",
      "202 2024-05-31            4   Philadelphia     334.0    23:59         7M8   \n",
      "\n",
      "     temperature_2m  relative_humidity_2m  precipitation  pressure_msl  \\\n",
      "0           18.9205                    49              0        1013.2   \n",
      "1           18.9205                    49              0        1013.2   \n",
      "2           17.1705                    56              0        1013.5   \n",
      "3           11.6205                    83              0        1014.8   \n",
      "4           11.6205                    83              0        1014.8   \n",
      "..              ...                   ...            ...           ...   \n",
      "198         21.3705                    44              0        1014.1   \n",
      "199         21.3705                    44              0        1014.1   \n",
      "200         21.3705                    44              0        1014.1   \n",
      "201         21.3705                    44              0        1014.1   \n",
      "202         21.3705                    44              0        1014.1   \n",
      "\n",
      "     cloud_cover  wind_speed_10m  \n",
      "0     1010.24250               0  \n",
      "1     1010.24250               0  \n",
      "2     1010.52380               0  \n",
      "3     1011.76190               0  \n",
      "4     1011.76190               0  \n",
      "..           ...             ...  \n",
      "198   1011.16425               1  \n",
      "199   1011.16425               1  \n",
      "200   1011.16425               1  \n",
      "201   1011.16425               1  \n",
      "202   1011.16425               1  \n",
      "\n",
      "[203 rows x 12 columns]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.119612Z",
     "start_time": "2024-05-18T11:14:08.118293Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ab05dbffd5252e55",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.123643Z",
     "start_time": "2024-05-18T11:14:08.120157Z"
    }
   },
   "cell_type": "code",
   "source": "df_holiday",
   "id": "1c8d5c15d9ad8135",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             ds                    holiday  holiday_status\n",
       "0    2023-01-01             New Year's Day            True\n",
       "1    2023-01-02  New Year's Day (observed)            True\n",
       "2    2023-01-03                        NaN           False\n",
       "3    2023-01-04                        NaN           False\n",
       "4    2023-01-05                        NaN           False\n",
       "..          ...                        ...             ...\n",
       "726  2024-12-27                        NaN           False\n",
       "727  2024-12-28                        NaN           False\n",
       "728  2024-12-29                        NaN           False\n",
       "729  2024-12-30                        NaN           False\n",
       "730  2024-12-31                        NaN           False\n",
       "\n",
       "[731 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>holiday</th>\n",
       "      <th>holiday_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>New Year's Day (observed)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.144590Z",
     "start_time": "2024-05-18T11:14:08.124244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_holiday['ds'] = pd.to_datetime(df_holiday['ds'])\n",
    "\n",
    "df_merged_weather = pd.merge(df_merged_weather, df_holiday[['ds', 'holiday_status']], left_on='FL_DATE', right_on='ds', how='left')\n",
    "df_merged_future_weather = pd.merge(df_merged_future_weather, df_holiday[['ds', 'holiday_status']], left_on='FL_DATE', right_on='ds', how='left')\n",
    "\n",
    "df_merged_weather['IS_HOLIDAY'] = df_merged_weather['holiday_status'].apply(lambda x: 1 if x else 0)\n",
    "df_merged_future_weather['IS_HOLIDAY'] = df_merged_future_weather['holiday_status'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "df_past_data = df_merged_weather.drop(columns=['ds', 'holiday_status'])\n",
    "df_future_data = df_merged_future_weather.drop(columns=['ds', 'holiday_status'])\n",
    "\n",
    "print(df_past_data)\n",
    "print(df_future_data)\n"
   ],
   "id": "146694561dd3b379",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         FL_DATE  DAY_OF_WEEK     DEST_CITY_NAME  AIR_TIME  DEP_TIME  \\\n",
      "0     2024-02-01            3             Boston     329.0  23:44:00   \n",
      "1     2024-02-01            3             Boston     314.0  08:17:00   \n",
      "2     2024-02-01            3             Denver     122.0  11:42:00   \n",
      "3     2024-02-01            3             Boston     314.0  13:30:00   \n",
      "4     2024-02-01            3          San Diego      66.0  08:27:00   \n",
      "...          ...          ...                ...       ...       ...   \n",
      "50234 2023-10-31            1        Albuquerque     115.0  11:04:00   \n",
      "50235 2023-10-31            1              Boise      70.0  08:34:00   \n",
      "50236 2023-10-31            1  Dallas/Fort Worth     184.0  10:58:00   \n",
      "50237 2023-10-31            1             Austin     185.0  08:37:00   \n",
      "50238 2023-10-31            1  Dallas/Fort Worth     180.0  18:17:00   \n",
      "\n",
      "      PLANE_MODEL  DEP_DEL15  temperature_2m  relative_humidity_2m  \\\n",
      "0             752          1         12.6315                    78   \n",
      "1             752          0         11.1815                    95   \n",
      "2             38M          1         10.8815                    94   \n",
      "3             752          1         11.4815                    90   \n",
      "4             39M          0         11.1815                    95   \n",
      "...           ...        ...             ...                   ...   \n",
      "50234         319          0          9.4815                    88   \n",
      "50235         319          0         14.6315                    51   \n",
      "50236         319          0         12.1315                    72   \n",
      "50237         319          0         14.6315                    51   \n",
      "50238         319          0         15.8815                    57   \n",
      "\n",
      "       precipitation  pressure_msl  cloud_cover  wind_speed_10m  IS_HOLIDAY  \n",
      "0                  0        1005.0   1002.00195              33           0  \n",
      "1                  0        1002.8    999.79320              89           0  \n",
      "2                  2        1003.6   1000.58760             100           0  \n",
      "3                  0        1003.0    999.99570             100           0  \n",
      "4                  0        1002.8    999.79320              89           0  \n",
      "...              ...           ...          ...             ...         ...  \n",
      "50234              0        1020.1   1017.02280              10           0  \n",
      "50235              0        1020.4   1017.37710               5           0  \n",
      "50236              0        1020.3   1017.25085               8           0  \n",
      "50237              0        1020.4   1017.37710               5           0  \n",
      "50238              0        1021.4   1018.38720              31           0  \n",
      "\n",
      "[50239 rows x 14 columns]\n",
      "       FL_DATE  DAY_OF_WEEK DEST_CITY_NAME  AIR_TIME DEP_TIME PLANE_MODEL  \\\n",
      "0   2024-05-31            4        Houston     236.0    00:30         7M9   \n",
      "1   2024-05-31            4         Manila     850.0    00:45         77W   \n",
      "2   2024-05-31            4        Chicago     260.0    01:10         739   \n",
      "3   2024-05-31            4        Houston     243.0    05:00         7M9   \n",
      "4   2024-05-31            4         Denver     157.0    05:00         753   \n",
      "..         ...          ...            ...       ...      ...         ...   \n",
      "198 2024-05-31            4         Taipei     800.0    23:45         777   \n",
      "199 2024-05-31            4      Hong Kong     850.0    23:50         77W   \n",
      "200 2024-05-31            4          Seoul     745.0    23:55         777   \n",
      "201 2024-05-31            4        Houston     235.0    23:59         777   \n",
      "202 2024-05-31            4   Philadelphia     334.0    23:59         7M8   \n",
      "\n",
      "     temperature_2m  relative_humidity_2m  precipitation  pressure_msl  \\\n",
      "0           18.9205                    49              0        1013.2   \n",
      "1           18.9205                    49              0        1013.2   \n",
      "2           17.1705                    56              0        1013.5   \n",
      "3           11.6205                    83              0        1014.8   \n",
      "4           11.6205                    83              0        1014.8   \n",
      "..              ...                   ...            ...           ...   \n",
      "198         21.3705                    44              0        1014.1   \n",
      "199         21.3705                    44              0        1014.1   \n",
      "200         21.3705                    44              0        1014.1   \n",
      "201         21.3705                    44              0        1014.1   \n",
      "202         21.3705                    44              0        1014.1   \n",
      "\n",
      "     cloud_cover  wind_speed_10m  IS_HOLIDAY  \n",
      "0     1010.24250               0           0  \n",
      "1     1010.24250               0           0  \n",
      "2     1010.52380               0           0  \n",
      "3     1011.76190               0           0  \n",
      "4     1011.76190               0           0  \n",
      "..           ...             ...         ...  \n",
      "198   1011.16425               1           0  \n",
      "199   1011.16425               1           0  \n",
      "200   1011.16425               1           0  \n",
      "201   1011.16425               1           0  \n",
      "202   1011.16425               1           0  \n",
      "\n",
      "[203 rows x 13 columns]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.151820Z",
     "start_time": "2024-05-18T11:14:08.145247Z"
    }
   },
   "cell_type": "code",
   "source": "df_past_data.query('IS_HOLIDAY == 1')",
   "id": "f829d6dec1c19db6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         FL_DATE  DAY_OF_WEEK DEST_CITY_NAME  AIR_TIME  DEP_TIME PLANE_MODEL  \\\n",
       "2030  2024-02-19            0     Washington     261.0  12:47:00         38M   \n",
       "2031  2024-02-19            0        Chicago     200.0  13:40:00      787-10   \n",
       "2032  2024-02-19            0         Newark     271.0  23:31:00       763ER   \n",
       "2033  2024-02-19            0         Boston     286.0  23:26:00         752   \n",
       "2034  2024-02-19            0         Newark     270.0  23:03:00       763ER   \n",
       "...          ...          ...            ...       ...       ...         ...   \n",
       "47240 2023-10-09            0       Portland      73.0  08:25:00         319   \n",
       "47241 2023-10-09            0      Santa Ana      61.0  13:21:00         319   \n",
       "47242 2023-10-09            0        Atlanta     256.0  23:40:00         319   \n",
       "47243 2023-10-09            0           Reno      37.0  16:43:00         319   \n",
       "47244 2023-10-09            0        Ontario      57.0  08:15:00         319   \n",
       "\n",
       "       DEP_DEL15  temperature_2m  relative_humidity_2m  precipitation  \\\n",
       "2030           1       12.781500                    92              0   \n",
       "2031           1       12.131500                    88              0   \n",
       "2032           1       14.381500                    79              0   \n",
       "2033           0       14.381500                    79              0   \n",
       "2034           1       14.381500                    79              0   \n",
       "...          ...             ...                   ...            ...   \n",
       "47240          0       14.331500                    90              0   \n",
       "47241          0       14.281500                    87              0   \n",
       "47242          1       19.481499                    68              0   \n",
       "47243          0       15.231500                    79              0   \n",
       "47244          0       14.331500                    90              0   \n",
       "\n",
       "       pressure_msl  cloud_cover  wind_speed_10m  IS_HOLIDAY  \n",
       "2030         1006.0   1003.00055              31           1  \n",
       "2031         1006.6   1003.59180              67           1  \n",
       "2032         1010.5   1007.50390              30           1  \n",
       "2033         1010.5   1007.50390              30           1  \n",
       "2034         1010.5   1007.50390              30           1  \n",
       "...             ...          ...             ...         ...  \n",
       "47240        1013.1   1010.09560             100           1  \n",
       "47241        1011.7   1008.69916             100           1  \n",
       "47242        1011.0   1008.05450             100           1  \n",
       "47243        1012.7   1009.70624              64           1  \n",
       "47244        1013.1   1010.09560             100           1  \n",
       "\n",
       "[1629 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>PLANE_MODEL</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>pressure_msl</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>IS_HOLIDAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>261.0</td>\n",
       "      <td>12:47:00</td>\n",
       "      <td>38M</td>\n",
       "      <td>1</td>\n",
       "      <td>12.781500</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>1003.00055</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>200.0</td>\n",
       "      <td>13:40:00</td>\n",
       "      <td>787-10</td>\n",
       "      <td>1</td>\n",
       "      <td>12.131500</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>1006.6</td>\n",
       "      <td>1003.59180</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>0</td>\n",
       "      <td>Newark</td>\n",
       "      <td>271.0</td>\n",
       "      <td>23:31:00</td>\n",
       "      <td>763ER</td>\n",
       "      <td>1</td>\n",
       "      <td>14.381500</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1010.5</td>\n",
       "      <td>1007.50390</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>286.0</td>\n",
       "      <td>23:26:00</td>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>14.381500</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1010.5</td>\n",
       "      <td>1007.50390</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>0</td>\n",
       "      <td>Newark</td>\n",
       "      <td>270.0</td>\n",
       "      <td>23:03:00</td>\n",
       "      <td>763ER</td>\n",
       "      <td>1</td>\n",
       "      <td>14.381500</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1010.5</td>\n",
       "      <td>1007.50390</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47240</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>0</td>\n",
       "      <td>Portland</td>\n",
       "      <td>73.0</td>\n",
       "      <td>08:25:00</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>14.331500</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1013.1</td>\n",
       "      <td>1010.09560</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47241</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>0</td>\n",
       "      <td>Santa Ana</td>\n",
       "      <td>61.0</td>\n",
       "      <td>13:21:00</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>14.281500</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1011.7</td>\n",
       "      <td>1008.69916</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47242</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>0</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>256.0</td>\n",
       "      <td>23:40:00</td>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>19.481499</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1008.05450</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47243</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>0</td>\n",
       "      <td>Reno</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16:43:00</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>15.231500</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1012.7</td>\n",
       "      <td>1009.70624</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47244</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>0</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>57.0</td>\n",
       "      <td>08:15:00</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>14.331500</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1013.1</td>\n",
       "      <td>1010.09560</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1629 rows × 14 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.314064Z",
     "start_time": "2024-05-18T11:14:08.152489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "past_data_path = '/Users/judith.rethmann/Documents/MBS/PredictiveAnalytics/Model/past_data.csv'\n",
    "df_past_data.to_csv(past_data_path, index=False)\n",
    "print(f\"past data file saved as '{past_data_path}'\")\n",
    "\n",
    "future_data_path = '/Users/judith.rethmann/Documents/MBS/PredictiveAnalytics/Model/future_data.csv'\n",
    "df_future_data.to_csv(future_data_path, index=False)\n",
    "print(f\"future data file saved as '{future_data_path}'\")"
   ],
   "id": "b504863dbf8687de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past data file saved as '/Users/judith.rethmann/Documents/MBS/PredictiveAnalytics/Model/past_data.csv'\n",
      "future data file saved as '/Users/judith.rethmann/Documents/MBS/PredictiveAnalytics/Model/future_data.csv'\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.320909Z",
     "start_time": "2024-05-18T11:14:08.314834Z"
    }
   },
   "cell_type": "code",
   "source": "df_past_data.info()",
   "id": "4ea7801e252f8943",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50239 entries, 0 to 50238\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   FL_DATE               50239 non-null  datetime64[ns]\n",
      " 1   DAY_OF_WEEK           50239 non-null  int32         \n",
      " 2   DEST_CITY_NAME        50239 non-null  object        \n",
      " 3   AIR_TIME              50239 non-null  float64       \n",
      " 4   DEP_TIME              50239 non-null  object        \n",
      " 5   PLANE_MODEL           50239 non-null  object        \n",
      " 6   DEP_DEL15             50239 non-null  int64         \n",
      " 7   temperature_2m        50239 non-null  float64       \n",
      " 8   relative_humidity_2m  50239 non-null  int64         \n",
      " 9   precipitation         50239 non-null  int64         \n",
      " 10  pressure_msl          50239 non-null  float64       \n",
      " 11  cloud_cover           50239 non-null  float64       \n",
      " 12  wind_speed_10m        50239 non-null  int64         \n",
      " 13  IS_HOLIDAY            50239 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int32(1), int64(5), object(3)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.325806Z",
     "start_time": "2024-05-18T11:14:08.321437Z"
    }
   },
   "cell_type": "code",
   "source": "df_past_data.head()",
   "id": "cc2705e6e18031fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     FL_DATE  DAY_OF_WEEK DEST_CITY_NAME  AIR_TIME  DEP_TIME PLANE_MODEL  \\\n",
       "0 2024-02-01            3         Boston     329.0  23:44:00         752   \n",
       "1 2024-02-01            3         Boston     314.0  08:17:00         752   \n",
       "2 2024-02-01            3         Denver     122.0  11:42:00         38M   \n",
       "3 2024-02-01            3         Boston     314.0  13:30:00         752   \n",
       "4 2024-02-01            3      San Diego      66.0  08:27:00         39M   \n",
       "\n",
       "   DEP_DEL15  temperature_2m  relative_humidity_2m  precipitation  \\\n",
       "0          1         12.6315                    78              0   \n",
       "1          0         11.1815                    95              0   \n",
       "2          1         10.8815                    94              2   \n",
       "3          1         11.4815                    90              0   \n",
       "4          0         11.1815                    95              0   \n",
       "\n",
       "   pressure_msl  cloud_cover  wind_speed_10m  IS_HOLIDAY  \n",
       "0        1005.0   1002.00195              33           0  \n",
       "1        1002.8    999.79320              89           0  \n",
       "2        1003.6   1000.58760             100           0  \n",
       "3        1003.0    999.99570             100           0  \n",
       "4        1002.8    999.79320              89           0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>PLANE_MODEL</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>pressure_msl</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>IS_HOLIDAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>3</td>\n",
       "      <td>Boston</td>\n",
       "      <td>329.0</td>\n",
       "      <td>23:44:00</td>\n",
       "      <td>752</td>\n",
       "      <td>1</td>\n",
       "      <td>12.6315</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1002.00195</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>3</td>\n",
       "      <td>Boston</td>\n",
       "      <td>314.0</td>\n",
       "      <td>08:17:00</td>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1815</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>1002.8</td>\n",
       "      <td>999.79320</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>3</td>\n",
       "      <td>Denver</td>\n",
       "      <td>122.0</td>\n",
       "      <td>11:42:00</td>\n",
       "      <td>38M</td>\n",
       "      <td>1</td>\n",
       "      <td>10.8815</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>1003.6</td>\n",
       "      <td>1000.58760</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>3</td>\n",
       "      <td>Boston</td>\n",
       "      <td>314.0</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>752</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4815</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>999.99570</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>3</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>66.0</td>\n",
       "      <td>08:27:00</td>\n",
       "      <td>39M</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1815</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>1002.8</td>\n",
       "      <td>999.79320</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BUILD MODEL",
   "id": "3db490a0a94fe3ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.328131Z",
     "start_time": "2024-05-18T11:14:08.326311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''df_past_data['FL_DATE'] = pd.to_datetime(df_past_data['FL_DATE'])\n",
    "\n",
    "df_prophet = df_past_data.rename(columns={'FL_DATE': 'ds', 'DEP_DEL15': 'y'})\n",
    "\n",
    "df_prophet = df_prophet[['ds', 'y']]\n",
    "\n",
    "train_size = int(len(df_prophet) * 0.7)\n",
    "train_df = df_prophet[:train_size]\n",
    "test_df = df_prophet[train_size:]\n",
    "'''"
   ],
   "id": "88efd73639b44a89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_past_data['FL_DATE'] = pd.to_datetime(df_past_data['FL_DATE'])\\n\\ndf_prophet = df_past_data.rename(columns={'FL_DATE': 'ds', 'DEP_DEL15': 'y'})\\n\\ndf_prophet = df_prophet[['ds', 'y']]\\n\\ntrain_size = int(len(df_prophet) * 0.7)\\ntrain_df = df_prophet[:train_size]\\ntest_df = df_prophet[train_size:]\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.330336Z",
     "start_time": "2024-05-18T11:14:08.328566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''model = Prophet()\n",
    "\n",
    "model.fit(train_df)'''"
   ],
   "id": "53848759f58d454d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = Prophet()\\n\\nmodel.fit(train_df)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.332509Z",
     "start_time": "2024-05-18T11:14:08.330878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''forecast_test = model.predict(test_df[['ds']])\n",
    "\n",
    "threshold = 0.5 \n",
    "forecast_test['yhat_binary'] = (forecast_test['yhat'] >= threshold).astype(int)\n",
    "\n",
    "forecast_test = forecast_test[['ds', 'yhat', 'yhat_binary']].merge(test_df, on='ds', how='left')\n",
    "'''"
   ],
   "id": "45e8072a6f13dd7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"forecast_test = model.predict(test_df[['ds']])\\n\\nthreshold = 0.5 \\nforecast_test['yhat_binary'] = (forecast_test['yhat'] >= threshold).astype(int)\\n\\nforecast_test = forecast_test[['ds', 'yhat', 'yhat_binary']].merge(test_df, on='ds', how='left')\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.334905Z",
     "start_time": "2024-05-18T11:14:08.333095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''print(\"Classification Report:\")\n",
    "print(classification_report(forecast_test['y'], forecast_test['yhat_binary']))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(forecast_test['y'], forecast_test['yhat_binary']))\n",
    "\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(forecast_test['y'], forecast_test['yhat_binary']))\n",
    "'''"
   ],
   "id": "1ae1070462b95202",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"Classification Report:\")\\nprint(classification_report(forecast_test[\\'y\\'], forecast_test[\\'yhat_binary\\']))\\n\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(forecast_test[\\'y\\'], forecast_test[\\'yhat_binary\\']))\\n\\nprint(\"Accuracy Score:\")\\nprint(accuracy_score(forecast_test[\\'y\\'], forecast_test[\\'yhat_binary\\']))\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prophet seems to struggle with binary classification, it is just predicting the majority class. I will try random forest",
   "id": "bbdc9e74c239c67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.341357Z",
     "start_time": "2024-05-18T11:14:08.339406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''df_past_data['year'] = df_past_data['FL_DATE'].dt.year\n",
    "df_past_data['month'] = df_past_data['FL_DATE'].dt.month\n",
    "df_past_data['day'] = df_past_data['FL_DATE'].dt.day\n",
    "df_past_data['dayofweek'] = df_past_data['FL_DATE'].dt.dayofweek\n",
    "\n",
    "features = ['year', 'month', 'day', 'dayofweek', 'temperature_2m', 'relative_humidity_2m', \n",
    "            'precipitation', 'pressure_msl', 'cloud_cover', 'wind_speed_10m', 'IS_HOLIDAY']\n",
    "\n",
    "X = df_past_data[features]\n",
    "y = df_past_data['DEP_DEL15']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "'''"
   ],
   "id": "a6fb78e18eec467c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_past_data[\\'year\\'] = df_past_data[\\'FL_DATE\\'].dt.year\\ndf_past_data[\\'month\\'] = df_past_data[\\'FL_DATE\\'].dt.month\\ndf_past_data[\\'day\\'] = df_past_data[\\'FL_DATE\\'].dt.day\\ndf_past_data[\\'dayofweek\\'] = df_past_data[\\'FL_DATE\\'].dt.dayofweek\\n\\nfeatures = [\\'year\\', \\'month\\', \\'day\\', \\'dayofweek\\', \\'temperature_2m\\', \\'relative_humidity_2m\\', \\n            \\'precipitation\\', \\'pressure_msl\\', \\'cloud_cover\\', \\'wind_speed_10m\\', \\'IS_HOLIDAY\\']\\n\\nX = df_past_data[features]\\ny = df_past_data[\\'DEP_DEL15\\']\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\nmodel = RandomForestClassifier(random_state=42)\\nmodel.fit(X_train, y_train)\\n\\ny_pred = model.predict(X_test)\\n\\nprint(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\n\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred))\\n\\nprint(\"Accuracy Score:\")\\nprint(accuracy_score(y_test, y_pred))\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.344162Z",
     "start_time": "2024-05-18T11:14:08.341814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''df_past_data['FL_DATE'] = pd.to_datetime(df_past_data['FL_DATE'])\n",
    "\n",
    "df_past_data['year'] = df_past_data['FL_DATE'].dt.year\n",
    "df_past_data['month'] = df_past_data['FL_DATE'].dt.month\n",
    "df_past_data['day'] = df_past_data['FL_DATE'].dt.day\n",
    "df_past_data['dayofweek'] = df_past_data['FL_DATE'].dt.dayofweek\n",
    "\n",
    "features = ['year', 'month', 'day', 'dayofweek', 'temperature_2m', 'relative_humidity_2m', \n",
    "            'precipitation', 'pressure_msl', 'cloud_cover', 'wind_speed_10m', 'IS_HOLIDAY']\n",
    "\n",
    "X = df_past_data[features]\n",
    "y = df_past_data['DEP_DEL15']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Random Forest Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred_xgb))\n",
    "\n",
    "gbc_model = GradientBoostingClassifier(random_state=42)\n",
    "gbc_model.fit(X_train, y_train)\n",
    "y_pred_gbc = gbc_model.predict(X_test)\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gbc))\n",
    "print(\"Gradient Boosting Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_gbc))\n",
    "print(\"Gradient Boosting Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred_gbc))\n",
    "'''"
   ],
   "id": "97420eb92f76775a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_past_data[\\'FL_DATE\\'] = pd.to_datetime(df_past_data[\\'FL_DATE\\'])\\n\\ndf_past_data[\\'year\\'] = df_past_data[\\'FL_DATE\\'].dt.year\\ndf_past_data[\\'month\\'] = df_past_data[\\'FL_DATE\\'].dt.month\\ndf_past_data[\\'day\\'] = df_past_data[\\'FL_DATE\\'].dt.day\\ndf_past_data[\\'dayofweek\\'] = df_past_data[\\'FL_DATE\\'].dt.dayofweek\\n\\nfeatures = [\\'year\\', \\'month\\', \\'day\\', \\'dayofweek\\', \\'temperature_2m\\', \\'relative_humidity_2m\\', \\n            \\'precipitation\\', \\'pressure_msl\\', \\'cloud_cover\\', \\'wind_speed_10m\\', \\'IS_HOLIDAY\\']\\n\\nX = df_past_data[features]\\ny = df_past_data[\\'DEP_DEL15\\']\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\nrf_model = RandomForestClassifier(random_state=42)\\nrf_model.fit(X_train, y_train)\\ny_pred_rf = rf_model.predict(X_test)\\nprint(\"Random Forest Classification Report:\")\\nprint(classification_report(y_test, y_pred_rf))\\nprint(\"Random Forest Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred_rf))\\nprint(\"Random Forest Accuracy Score:\")\\nprint(accuracy_score(y_test, y_pred_rf))\\n\\nxgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\\'logloss\\', random_state=42)\\nxgb_model.fit(X_train, y_train)\\ny_pred_xgb = xgb_model.predict(X_test)\\nprint(\"XGBoost Classification Report:\")\\nprint(classification_report(y_test, y_pred_xgb))\\nprint(\"XGBoost Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred_xgb))\\nprint(\"XGBoost Accuracy Score:\")\\nprint(accuracy_score(y_test, y_pred_xgb))\\n\\ngbc_model = GradientBoostingClassifier(random_state=42)\\ngbc_model.fit(X_train, y_train)\\ny_pred_gbc = gbc_model.predict(X_test)\\nprint(\"Gradient Boosting Classification Report:\")\\nprint(classification_report(y_test, y_pred_gbc))\\nprint(\"Gradient Boosting Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred_gbc))\\nprint(\"Gradient Boosting Accuracy Score:\")\\nprint(accuracy_score(y_test, y_pred_gbc))\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.346962Z",
     "start_time": "2024-05-18T11:14:08.344618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''df_past_data['FL_DATE'] = pd.to_datetime(df_past_data['FL_DATE'])\n",
    "\n",
    "df_past_data['year'] = df_past_data['FL_DATE'].dt.year\n",
    "df_past_data['month'] = df_past_data['FL_DATE'].dt.month\n",
    "df_past_data['day'] = df_past_data['FL_DATE'].dt.day\n",
    "df_past_data['dayofweek'] = df_past_data['FL_DATE'].dt.dayofweek\n",
    "\n",
    "features = ['year', 'month', 'day', 'dayofweek', 'temperature_2m', 'relative_humidity_2m', \n",
    "            'precipitation', 'pressure_msl', 'cloud_cover', 'wind_speed_10m', 'IS_HOLIDAY']\n",
    "\n",
    "X = df_past_data[features]\n",
    "y = df_past_data['DEP_DEL15']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_xgb_model = xgb.XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_best_xgb = best_xgb_model.predict(X_test)\n",
    "\n",
    "print(\"Best XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best_xgb))\n",
    "\n",
    "print(\"Best XGBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best_xgb))\n",
    "\n",
    "print(\"Best XGBoost Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred_best_xgb))\n",
    "'''"
   ],
   "id": "18b77f7887ba6578",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_past_data[\\'FL_DATE\\'] = pd.to_datetime(df_past_data[\\'FL_DATE\\'])\\n\\ndf_past_data[\\'year\\'] = df_past_data[\\'FL_DATE\\'].dt.year\\ndf_past_data[\\'month\\'] = df_past_data[\\'FL_DATE\\'].dt.month\\ndf_past_data[\\'day\\'] = df_past_data[\\'FL_DATE\\'].dt.day\\ndf_past_data[\\'dayofweek\\'] = df_past_data[\\'FL_DATE\\'].dt.dayofweek\\n\\nfeatures = [\\'year\\', \\'month\\', \\'day\\', \\'dayofweek\\', \\'temperature_2m\\', \\'relative_humidity_2m\\', \\n            \\'precipitation\\', \\'pressure_msl\\', \\'cloud_cover\\', \\'wind_speed_10m\\', \\'IS_HOLIDAY\\']\\n\\nX = df_past_data[features]\\ny = df_past_data[\\'DEP_DEL15\\']\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\nparam_grid = {\\n    \\'n_estimators\\': [100, 200, 300],\\n    \\'max_depth\\': [3, 5, 7],\\n    \\'learning_rate\\': [0.01, 0.05, 0.1],\\n    \\'subsample\\': [0.7, 0.8, 0.9],\\n    \\'colsample_bytree\\': [0.7, 0.8, 0.9]\\n}\\n\\nxgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\\'logloss\\', random_state=42)\\n\\ngrid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \\n                           scoring=\\'accuracy\\', cv=3, verbose=1, n_jobs=-1)\\n\\ngrid_search.fit(X_train, y_train)\\n\\nprint(\"Best Parameters:\", grid_search.best_params_)\\nprint(\"Best Score:\", grid_search.best_score_)\\n\\nbest_params = grid_search.best_params_\\nbest_xgb_model = xgb.XGBClassifier(**best_params, use_label_encoder=False, eval_metric=\\'logloss\\', random_state=42)\\nbest_xgb_model.fit(X_train, y_train)\\n\\ny_pred_best_xgb = best_xgb_model.predict(X_test)\\n\\nprint(\"Best XGBoost Classification Report:\")\\nprint(classification_report(y_test, y_pred_best_xgb))\\n\\nprint(\"Best XGBoost Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred_best_xgb))\\n\\nprint(\"Best XGBoost Accuracy Score:\")\\nprint(accuracy_score(y_test, y_pred_best_xgb))\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### although xg boost performed best, it is not performing well on actually delayed flights. Random Forest was better for this. I will first try weighting false negatives higher and otherwise go with random forest",
   "id": "471214b1914ee106"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:14:08.349675Z",
     "start_time": "2024-05-18T11:14:08.347444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''df_past_data['FL_DATE'] = pd.to_datetime(df_past_data['FL_DATE'])\n",
    "\n",
    "df_past_data['year'] = df_past_data['FL_DATE'].dt.year\n",
    "df_past_data['month'] = df_past_data['FL_DATE'].dt.month\n",
    "df_past_data['day'] = df_past_data['FL_DATE'].dt.day\n",
    "df_past_data['dayofweek'] = df_past_data['FL_DATE'].dt.dayofweek\n",
    "\n",
    "features = ['year', 'month', 'day', 'dayofweek', 'temperature_2m', 'relative_humidity_2m', \n",
    "            'precipitation', 'pressure_msl', 'cloud_cover', 'wind_speed_10m', 'IS_HOLIDAY']\n",
    "\n",
    "X = df_past_data[features]\n",
    "y = df_past_data['DEP_DEL15']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "print(\"Class Weights:\", class_weight_dict)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(scale_pos_weight=class_weight_dict[1] / class_weight_dict[0], \n",
    "                              use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_xgb_model = xgb.XGBClassifier(**best_params, scale_pos_weight=class_weight_dict[1] / class_weight_dict[0], \n",
    "                                   use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_best_xgb = best_xgb_model.predict(X_test)\n",
    "\n",
    "print(\"Best XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best_xgb))\n",
    "\n",
    "print(\"Best XGBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best_xgb))\n",
    "\n",
    "print(\"Best XGBoost Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred_best_xgb))\n",
    "'''"
   ],
   "id": "186d29c1dc80de08",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_past_data[\\'FL_DATE\\'] = pd.to_datetime(df_past_data[\\'FL_DATE\\'])\\n\\ndf_past_data[\\'year\\'] = df_past_data[\\'FL_DATE\\'].dt.year\\ndf_past_data[\\'month\\'] = df_past_data[\\'FL_DATE\\'].dt.month\\ndf_past_data[\\'day\\'] = df_past_data[\\'FL_DATE\\'].dt.day\\ndf_past_data[\\'dayofweek\\'] = df_past_data[\\'FL_DATE\\'].dt.dayofweek\\n\\nfeatures = [\\'year\\', \\'month\\', \\'day\\', \\'dayofweek\\', \\'temperature_2m\\', \\'relative_humidity_2m\\', \\n            \\'precipitation\\', \\'pressure_msl\\', \\'cloud_cover\\', \\'wind_speed_10m\\', \\'IS_HOLIDAY\\']\\n\\nX = df_past_data[features]\\ny = df_past_data[\\'DEP_DEL15\\']\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\nclass_weights = compute_class_weight(\\'balanced\\', classes=np.unique(y_train), y=y_train)\\nclass_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\\nprint(\"Class Weights:\", class_weight_dict)\\n\\nparam_grid = {\\n    \\'n_estimators\\': [100, 200, 300],\\n    \\'max_depth\\': [3, 5, 7],\\n    \\'learning_rate\\': [0.01, 0.05, 0.1],\\n    \\'subsample\\': [0.7, 0.8, 0.9],\\n    \\'colsample_bytree\\': [0.7, 0.8, 0.9]\\n}\\n\\nxgb_model = xgb.XGBClassifier(scale_pos_weight=class_weight_dict[1] / class_weight_dict[0], \\n                              use_label_encoder=False, eval_metric=\\'logloss\\', random_state=42)\\n\\ngrid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \\n                           scoring=\\'accuracy\\', cv=3, verbose=1, n_jobs=-1)\\n\\ngrid_search.fit(X_train, y_train)\\n\\nprint(\"Best Parameters:\", grid_search.best_params_)\\nprint(\"Best Score:\", grid_search.best_score_)\\n\\nbest_params = grid_search.best_params_\\nbest_xgb_model = xgb.XGBClassifier(**best_params, scale_pos_weight=class_weight_dict[1] / class_weight_dict[0], \\n                                   use_label_encoder=False, eval_metric=\\'logloss\\', random_state=42)\\nbest_xgb_model.fit(X_train, y_train)\\n\\ny_pred_best_xgb = best_xgb_model.predict(X_test)\\n\\nprint(\"Best XGBoost Classification Report:\")\\nprint(classification_report(y_test, y_pred_best_xgb))\\n\\nprint(\"Best XGBoost Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred_best_xgb))\\n\\nprint(\"Best XGBoost Accuracy Score:\")\\nprint(accuracy_score(y_test, y_pred_best_xgb))\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### This lowererd the performance. I will go with random forest instead",
   "id": "b37a2460196b2674"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:18:21.687450Z",
     "start_time": "2024-05-18T11:14:08.350191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''df_past_data['FL_DATE'] = pd.to_datetime(df_past_data['FL_DATE'])\n",
    "\n",
    "df_past_data['year'] = df_past_data['FL_DATE'].dt.year\n",
    "df_past_data['month'] = df_past_data['FL_DATE'].dt.month\n",
    "df_past_data['day'] = df_past_data['FL_DATE'].dt.day\n",
    "df_past_data['dayofweek'] = df_past_data['FL_DATE'].dt.dayofweek\n",
    "\n",
    "features = ['year', 'month', 'day', 'dayofweek', 'temperature_2m', 'relative_humidity_2m', \n",
    "            'precipitation', 'pressure_msl', 'cloud_cover', 'wind_speed_10m', 'IS_HOLIDAY']\n",
    "\n",
    "X = df_past_data[features]\n",
    "y = df_past_data['DEP_DEL15']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_best_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "print(\"Best Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best_rf))\n",
    "\n",
    "print(\"Best Random Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best_rf))\n",
    "\n",
    "print(\"Best Random Forest Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred_best_rf))\n",
    "'''"
   ],
   "id": "67a17e1fd955ee4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/judith.rethmann/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[43], line 29\u001B[0m\n\u001B[1;32m     24\u001B[0m rf_model \u001B[38;5;241m=\u001B[39m RandomForestClassifier(random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m     26\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mrf_model, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, \n\u001B[1;32m     27\u001B[0m                            scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 29\u001B[0m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest Parameters:\u001B[39m\u001B[38;5;124m\"\u001B[39m, grid_search\u001B[38;5;241m.\u001B[39mbest_params_)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest Score:\u001B[39m\u001B[38;5;124m\"\u001B[39m, grid_search\u001B[38;5;241m.\u001B[39mbest_score_)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1472\u001B[0m     )\n\u001B[1;32m   1473\u001B[0m ):\n\u001B[0;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    966\u001B[0m     )\n\u001B[1;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 970\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1527\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:916\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    909\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    911\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    912\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    913\u001B[0m         )\n\u001B[1;32m    914\u001B[0m     )\n\u001B[0;32m--> 916\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    929\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    930\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    931\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    936\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    937\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    938\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    939\u001B[0m     )\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     66\u001B[0m )\n\u001B[0;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/joblib/parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[1;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[1;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[1;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[1;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/joblib/parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[0;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[1;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[1;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[1;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[1;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[1;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[1;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/joblib/parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[1;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[0;32m-> 1762\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[1;32m   1766\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[1;32m   1767\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### not bad. I will try optimizing with the f1 score to find a better balance the true and false positives",
   "id": "f68abad50d76ef5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:18:21.688388Z",
     "start_time": "2024-05-18T11:18:21.688322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''features = ['year', 'month', 'day', 'dayofweek', 'temperature_2m', 'relative_humidity_2m', \n",
    "            'precipitation', 'pressure_msl', 'cloud_cover', 'wind_speed_10m', 'IS_HOLIDAY']\n",
    "\n",
    "X = df_past_data[features]\n",
    "y = df_past_data['DEP_DEL15']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, \n",
    "                           scoring='f1', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_best_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "print(\"Best Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best_rf))\n",
    "\n",
    "print(\"Best Random Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best_rf))\n",
    "\n",
    "print(\"Best Random Forest Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred_best_rf))'''"
   ],
   "id": "40263ea6f6bc3dcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### this has a slightly lower accuracy, but performs better on the actually delayed flights. I will try some other features and maybe oversample",
   "id": "87562a22c636145e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_past_data.info()",
   "id": "e446c53b44942678",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''df_past_data['FL_DATE'] = pd.to_datetime(df_past_data['FL_DATE'])\n",
    "\n",
    "df_past_data['DEP_TIME'] = pd.to_datetime(df_past_data['DEP_TIME'], format='%H:%M:%S', errors='coerce')\n",
    "df_past_data['DEP_HOUR'] = df_past_data['DEP_TIME'].dt.hour\n",
    "df_past_data['DEP_MINUTE'] = df_past_data['DEP_TIME'].dt.minute\n",
    "\n",
    "features = ['DEST_CITY_NAME', 'AIR_TIME', 'DEP_HOUR', 'DEP_MINUTE', 'PLANE_MODEL', \n",
    "            'temperature_2m', 'relative_humidity_2m', 'precipitation', 'pressure_msl', \n",
    "            'cloud_cover', 'wind_speed_10m', 'IS_HOLIDAY', 'year', 'month', 'day', 'dayofweek']\n",
    "\n",
    "X = df_past_data[features]\n",
    "y = df_past_data['DEP_DEL15']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "categorical_features = ['DEST_CITY_NAME', 'PLANE_MODEL']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "numeric_features = ['AIR_TIME', 'DEP_HOUR', 'DEP_MINUTE', 'temperature_2m', 'relative_humidity_2m', \n",
    "                    'precipitation', 'pressure_msl', 'cloud_cover', 'wind_speed_10m', \n",
    "                    'IS_HOLIDAY', 'year', 'month', 'day', 'dayofweek']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, \n",
    "                           scoring='f1', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = RandomForestClassifier(\n",
    "    n_estimators=best_params['classifier__n_estimators'],\n",
    "    max_depth=best_params['classifier__max_depth'],\n",
    "    min_samples_split=best_params['classifier__min_samples_split'],\n",
    "    min_samples_leaf=best_params['classifier__min_samples_leaf'],\n",
    "    bootstrap=best_params['classifier__bootstrap'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train_res = preprocessor.fit_transform(X_train_res)\n",
    "\n",
    "best_rf_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "y_pred_best_rf = best_rf_model.predict(X_test_preprocessed)\n",
    "\n",
    "print(\"Best Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best_rf))\n",
    "\n",
    "print(\"Best Random Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best_rf))\n",
    "\n",
    "print(\"Best Random Forest Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred_best_rf))\n",
    "\n",
    "feature_importances = best_rf_model.feature_importances_\n",
    "\n",
    "feature_names = numeric_features + list(preprocessor.transformers_[1][1].get_feature_names_out(categorical_features))\n",
    "\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importances_df)\n",
    "'''"
   ],
   "id": "4921b5aef742ec22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### It seems like I applied smote before the processing which cause issues. to cut down the run time I will use the best parameters when I fix the issue",
   "id": "2de991d3a09f32aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:22:10.888400Z",
     "start_time": "2024-05-18T11:20:25.906837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_past_data['FL_DATE'] = pd.to_datetime(df_past_data['FL_DATE'])\n",
    "\n",
    "df_past_data['DEP_TIME'] = pd.to_datetime(df_past_data['DEP_TIME'], format='%H:%M:%S', errors='coerce')\n",
    "df_past_data['DEP_HOUR'] = df_past_data['DEP_TIME'].dt.hour\n",
    "df_past_data['DEP_MINUTE'] = df_past_data['DEP_TIME'].dt.minute\n",
    "\n",
    "features = ['DEST_CITY_NAME', 'AIR_TIME', 'DEP_HOUR', 'DEP_MINUTE', 'PLANE_MODEL', \n",
    "            'temperature_2m', 'relative_humidity_2m', 'precipitation', 'pressure_msl', \n",
    "            'cloud_cover', 'wind_speed_10m', 'IS_HOLIDAY', 'year', 'month', 'day', 'dayofweek']\n",
    "\n",
    "X = df_past_data[features]\n",
    "y = df_past_data['DEP_DEL15']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "categorical_features = ['DEST_CITY_NAME', 'PLANE_MODEL']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "numeric_features = ['AIR_TIME', 'DEP_HOUR', 'DEP_MINUTE', 'temperature_2m', 'relative_humidity_2m', \n",
    "                    'precipitation', 'pressure_msl', 'cloud_cover', 'wind_speed_10m', \n",
    "                    'IS_HOLIDAY', 'year', 'month', 'day', 'dayofweek']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Train the Random Forest model with the best parameters\n",
    "best_rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    bootstrap=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to the preprocessed training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "# Train the model on the resampled and preprocessed training data\n",
    "best_rf_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred_best_rf = best_rf_model.predict(X_test_preprocessed)\n",
    "\n",
    "print(\"Best Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best_rf))\n",
    "\n",
    "print(\"Best Random Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best_rf))\n",
    "\n",
    "print(\"Best Random Forest Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred_best_rf))\n",
    "\n",
    "feature_importances = best_rf_model.feature_importances_\n",
    "\n",
    "feature_names = numeric_features + list(preprocessor.transformers_[1][1].get_feature_names_out(categorical_features))\n",
    "\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "display(feature_importances_df)\n"
   ],
   "id": "6a85cc71bfa62c32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91     11849\n",
      "           1       0.80      0.35      0.48      3223\n",
      "\n",
      "    accuracy                           0.84     15072\n",
      "   macro avg       0.82      0.66      0.69     15072\n",
      "weighted avg       0.84      0.84      0.82     15072\n",
      "\n",
      "Best Random Forest Confusion Matrix:\n",
      "[[11569   280]\n",
      " [ 2110  1113]]\n",
      "Best Random Forest Accuracy Score:\n",
      "0.8414278131634819\n",
      "Feature Importances:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                      feature  importance\n",
       "1                    DEP_HOUR    0.125493\n",
       "2                  DEP_MINUTE    0.074349\n",
       "11                      month    0.066651\n",
       "72            PLANE_MODEL_39M    0.062609\n",
       "0                    AIR_TIME    0.058889\n",
       "..                        ...         ...\n",
       "23     DEST_CITY_NAME_Burbank    0.000089\n",
       "32      DEST_CITY_NAME_Fresno    0.000063\n",
       "45     DEST_CITY_NAME_Madison    0.000044\n",
       "38   DEST_CITY_NAME_Kalispell    0.000036\n",
       "44  DEST_CITY_NAME_Louisville    0.000024\n",
       "\n",
       "[84 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEP_HOUR</td>\n",
       "      <td>0.125493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEP_MINUTE</td>\n",
       "      <td>0.074349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>month</td>\n",
       "      <td>0.066651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>PLANE_MODEL_39M</td>\n",
       "      <td>0.062609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIR_TIME</td>\n",
       "      <td>0.058889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DEST_CITY_NAME_Burbank</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DEST_CITY_NAME_Fresno</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DEST_CITY_NAME_Madison</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DEST_CITY_NAME_Kalispell</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DEST_CITY_NAME_Louisville</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:22:10.892839Z",
     "start_time": "2024-05-18T11:22:10.889463Z"
    }
   },
   "cell_type": "code",
   "source": "feature_importances_df",
   "id": "92ddec9216c357c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      feature  importance\n",
       "1                    DEP_HOUR    0.125493\n",
       "2                  DEP_MINUTE    0.074349\n",
       "11                      month    0.066651\n",
       "72            PLANE_MODEL_39M    0.062609\n",
       "0                    AIR_TIME    0.058889\n",
       "..                        ...         ...\n",
       "23     DEST_CITY_NAME_Burbank    0.000089\n",
       "32      DEST_CITY_NAME_Fresno    0.000063\n",
       "45     DEST_CITY_NAME_Madison    0.000044\n",
       "38   DEST_CITY_NAME_Kalispell    0.000036\n",
       "44  DEST_CITY_NAME_Louisville    0.000024\n",
       "\n",
       "[84 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEP_HOUR</td>\n",
       "      <td>0.125493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEP_MINUTE</td>\n",
       "      <td>0.074349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>month</td>\n",
       "      <td>0.066651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>PLANE_MODEL_39M</td>\n",
       "      <td>0.062609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIR_TIME</td>\n",
       "      <td>0.058889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DEST_CITY_NAME_Burbank</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DEST_CITY_NAME_Fresno</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DEST_CITY_NAME_Madison</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DEST_CITY_NAME_Kalispell</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DEST_CITY_NAME_Louisville</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:22:10.897915Z",
     "start_time": "2024-05-18T11:22:10.893520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)  # Show full width of each column\n",
    "pd.set_option('display.expand_frame_repr', False)  # Don't wrap rows\n",
    "\n",
    "# Assuming 'feature_importances_df' is your DataFrame\n",
    "display(feature_importances_df)"
   ],
   "id": "d5e32b7b5496652e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             feature  importance\n",
       "1                           DEP_HOUR    0.125493\n",
       "2                         DEP_MINUTE    0.074349\n",
       "11                             month    0.066651\n",
       "72                   PLANE_MODEL_39M    0.062609\n",
       "0                           AIR_TIME    0.058889\n",
       "3                     temperature_2m    0.047835\n",
       "4               relative_humidity_2m    0.046565\n",
       "7                        cloud_cover    0.043287\n",
       "6                       pressure_msl    0.042049\n",
       "8                     wind_speed_10m    0.041447\n",
       "13                         dayofweek    0.040412\n",
       "71                   PLANE_MODEL_38M    0.039444\n",
       "12                               day    0.038357\n",
       "70                   PLANE_MODEL_319    0.032078\n",
       "74                 PLANE_MODEL_739ER    0.031693\n",
       "76                   PLANE_MODEL_753    0.023930\n",
       "10                              year    0.019163\n",
       "51             DEST_CITY_NAME_Newark    0.013231\n",
       "77                 PLANE_MODEL_763ER    0.010680\n",
       "5                      precipitation    0.008111\n",
       "69         DEST_CITY_NAME_Washington    0.007055\n",
       "34            DEST_CITY_NAME_Houston    0.006766\n",
       "24            DEST_CITY_NAME_Chicago    0.006059\n",
       "41          DEST_CITY_NAME_Las Vegas    0.006056\n",
       "82                 PLANE_MODEL_787-8    0.006004\n",
       "33           DEST_CITY_NAME_Honolulu    0.005737\n",
       "64          DEST_CITY_NAME_San Diego    0.005482\n",
       "28             DEST_CITY_NAME_Denver    0.005004\n",
       "21             DEST_CITY_NAME_Boston    0.004949\n",
       "75                   PLANE_MODEL_752    0.004924\n",
       "43        DEST_CITY_NAME_Los Angeles    0.004462\n",
       "9                         IS_HOLIDAY    0.004265\n",
       "67            DEST_CITY_NAME_Seattle    0.004081\n",
       "57            DEST_CITY_NAME_Phoenix    0.003619\n",
       "59           DEST_CITY_NAME_Portland    0.003443\n",
       "79                 PLANE_MODEL_772ER    0.002970\n",
       "27  DEST_CITY_NAME_Dallas/Fort Worth    0.002957\n",
       "17             DEST_CITY_NAME_Austin    0.002852\n",
       "40               DEST_CITY_NAME_Kona    0.002478\n",
       "65          DEST_CITY_NAME_Santa Ana    0.002445\n",
       "16            DEST_CITY_NAME_Atlanta    0.002400\n",
       "37            DEST_CITY_NAME_Kahului    0.002220\n",
       "29             DEST_CITY_NAME_Eugene    0.001808\n",
       "60     DEST_CITY_NAME_Raleigh/Durham    0.001806\n",
       "58         DEST_CITY_NAME_Pittsburgh    0.001799\n",
       "83                 PLANE_MODEL_787-9    0.001707\n",
       "54            DEST_CITY_NAME_Orlando    0.001699\n",
       "49          DEST_CITY_NAME_Nashville    0.001628\n",
       "25          DEST_CITY_NAME_Cleveland    0.001597\n",
       "62     DEST_CITY_NAME_Salt Lake City    0.001535\n",
       "50        DEST_CITY_NAME_New Orleans    0.001456\n",
       "35       DEST_CITY_NAME_Indianapolis    0.001393\n",
       "18          DEST_CITY_NAME_Baltimore    0.001346\n",
       "68              DEST_CITY_NAME_Tampa    0.001297\n",
       "14        DEST_CITY_NAME_Albuquerque    0.001257\n",
       "19       DEST_CITY_NAME_Bend/Redmond    0.001232\n",
       "66      DEST_CITY_NAME_Santa Barbara    0.001156\n",
       "30    DEST_CITY_NAME_Fort Lauderdale    0.001041\n",
       "56       DEST_CITY_NAME_Philadelphia    0.001030\n",
       "22            DEST_CITY_NAME_Bozeman    0.000947\n",
       "39        DEST_CITY_NAME_Kansas City    0.000940\n",
       "42              DEST_CITY_NAME_Lihue    0.000937\n",
       "47              DEST_CITY_NAME_Miami    0.000873\n",
       "52              DEST_CITY_NAME_Omaha    0.000816\n",
       "63        DEST_CITY_NAME_San Antonio    0.000807\n",
       "48        DEST_CITY_NAME_Minneapolis    0.000798\n",
       "46            DEST_CITY_NAME_Medford    0.000796\n",
       "20              DEST_CITY_NAME_Boise    0.000780\n",
       "26           DEST_CITY_NAME_Columbus    0.000745\n",
       "55       DEST_CITY_NAME_Palm Springs    0.000669\n",
       "61               DEST_CITY_NAME_Reno    0.000634\n",
       "53            DEST_CITY_NAME_Ontario    0.000599\n",
       "36            DEST_CITY_NAME_Jackson    0.000466\n",
       "15          DEST_CITY_NAME_Anchorage    0.000429\n",
       "73                   PLANE_MODEL_738    0.000390\n",
       "81                PLANE_MODEL_787-10    0.000350\n",
       "31         DEST_CITY_NAME_Fort Myers    0.000189\n",
       "80                   PLANE_MODEL_77W    0.000147\n",
       "78                 PLANE_MODEL_764ER    0.000145\n",
       "23            DEST_CITY_NAME_Burbank    0.000089\n",
       "32             DEST_CITY_NAME_Fresno    0.000063\n",
       "45            DEST_CITY_NAME_Madison    0.000044\n",
       "38          DEST_CITY_NAME_Kalispell    0.000036\n",
       "44         DEST_CITY_NAME_Louisville    0.000024"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEP_HOUR</td>\n",
       "      <td>0.125493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEP_MINUTE</td>\n",
       "      <td>0.074349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>month</td>\n",
       "      <td>0.066651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>PLANE_MODEL_39M</td>\n",
       "      <td>0.062609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIR_TIME</td>\n",
       "      <td>0.058889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>temperature_2m</td>\n",
       "      <td>0.047835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relative_humidity_2m</td>\n",
       "      <td>0.046565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cloud_cover</td>\n",
       "      <td>0.043287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pressure_msl</td>\n",
       "      <td>0.042049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wind_speed_10m</td>\n",
       "      <td>0.041447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dayofweek</td>\n",
       "      <td>0.040412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>PLANE_MODEL_38M</td>\n",
       "      <td>0.039444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>day</td>\n",
       "      <td>0.038357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>PLANE_MODEL_319</td>\n",
       "      <td>0.032078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>PLANE_MODEL_739ER</td>\n",
       "      <td>0.031693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>PLANE_MODEL_753</td>\n",
       "      <td>0.023930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>year</td>\n",
       "      <td>0.019163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DEST_CITY_NAME_Newark</td>\n",
       "      <td>0.013231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>PLANE_MODEL_763ER</td>\n",
       "      <td>0.010680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>0.008111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>DEST_CITY_NAME_Washington</td>\n",
       "      <td>0.007055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DEST_CITY_NAME_Houston</td>\n",
       "      <td>0.006766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DEST_CITY_NAME_Chicago</td>\n",
       "      <td>0.006059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DEST_CITY_NAME_Las Vegas</td>\n",
       "      <td>0.006056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>PLANE_MODEL_787-8</td>\n",
       "      <td>0.006004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DEST_CITY_NAME_Honolulu</td>\n",
       "      <td>0.005737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>DEST_CITY_NAME_San Diego</td>\n",
       "      <td>0.005482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DEST_CITY_NAME_Denver</td>\n",
       "      <td>0.005004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DEST_CITY_NAME_Boston</td>\n",
       "      <td>0.004949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>PLANE_MODEL_752</td>\n",
       "      <td>0.004924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DEST_CITY_NAME_Los Angeles</td>\n",
       "      <td>0.004462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IS_HOLIDAY</td>\n",
       "      <td>0.004265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>DEST_CITY_NAME_Seattle</td>\n",
       "      <td>0.004081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DEST_CITY_NAME_Phoenix</td>\n",
       "      <td>0.003619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>DEST_CITY_NAME_Portland</td>\n",
       "      <td>0.003443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>PLANE_MODEL_772ER</td>\n",
       "      <td>0.002970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DEST_CITY_NAME_Dallas/Fort Worth</td>\n",
       "      <td>0.002957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DEST_CITY_NAME_Austin</td>\n",
       "      <td>0.002852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DEST_CITY_NAME_Kona</td>\n",
       "      <td>0.002478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>DEST_CITY_NAME_Santa Ana</td>\n",
       "      <td>0.002445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DEST_CITY_NAME_Atlanta</td>\n",
       "      <td>0.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DEST_CITY_NAME_Kahului</td>\n",
       "      <td>0.002220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DEST_CITY_NAME_Eugene</td>\n",
       "      <td>0.001808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>DEST_CITY_NAME_Raleigh/Durham</td>\n",
       "      <td>0.001806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>DEST_CITY_NAME_Pittsburgh</td>\n",
       "      <td>0.001799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>PLANE_MODEL_787-9</td>\n",
       "      <td>0.001707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>DEST_CITY_NAME_Orlando</td>\n",
       "      <td>0.001699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>DEST_CITY_NAME_Nashville</td>\n",
       "      <td>0.001628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DEST_CITY_NAME_Cleveland</td>\n",
       "      <td>0.001597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>DEST_CITY_NAME_Salt Lake City</td>\n",
       "      <td>0.001535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>DEST_CITY_NAME_New Orleans</td>\n",
       "      <td>0.001456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DEST_CITY_NAME_Indianapolis</td>\n",
       "      <td>0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DEST_CITY_NAME_Baltimore</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>DEST_CITY_NAME_Tampa</td>\n",
       "      <td>0.001297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DEST_CITY_NAME_Albuquerque</td>\n",
       "      <td>0.001257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DEST_CITY_NAME_Bend/Redmond</td>\n",
       "      <td>0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>DEST_CITY_NAME_Santa Barbara</td>\n",
       "      <td>0.001156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DEST_CITY_NAME_Fort Lauderdale</td>\n",
       "      <td>0.001041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>DEST_CITY_NAME_Philadelphia</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DEST_CITY_NAME_Bozeman</td>\n",
       "      <td>0.000947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DEST_CITY_NAME_Kansas City</td>\n",
       "      <td>0.000940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DEST_CITY_NAME_Lihue</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>DEST_CITY_NAME_Miami</td>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>DEST_CITY_NAME_Omaha</td>\n",
       "      <td>0.000816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>DEST_CITY_NAME_San Antonio</td>\n",
       "      <td>0.000807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>DEST_CITY_NAME_Minneapolis</td>\n",
       "      <td>0.000798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DEST_CITY_NAME_Medford</td>\n",
       "      <td>0.000796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DEST_CITY_NAME_Boise</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DEST_CITY_NAME_Columbus</td>\n",
       "      <td>0.000745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>DEST_CITY_NAME_Palm Springs</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>DEST_CITY_NAME_Reno</td>\n",
       "      <td>0.000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>DEST_CITY_NAME_Ontario</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DEST_CITY_NAME_Jackson</td>\n",
       "      <td>0.000466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DEST_CITY_NAME_Anchorage</td>\n",
       "      <td>0.000429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>PLANE_MODEL_738</td>\n",
       "      <td>0.000390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>PLANE_MODEL_787-10</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DEST_CITY_NAME_Fort Myers</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>PLANE_MODEL_77W</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>PLANE_MODEL_764ER</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DEST_CITY_NAME_Burbank</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DEST_CITY_NAME_Fresno</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DEST_CITY_NAME_Madison</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DEST_CITY_NAME_Kalispell</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DEST_CITY_NAME_Louisville</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:22:10.901383Z",
     "start_time": "2024-05-18T11:22:10.898994Z"
    }
   },
   "cell_type": "code",
   "source": "feature_importances_df.to_csv('feature_importances.csv', index=False)",
   "id": "25963fb5e8955bb",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### I will leave it at this. Next, I will use the model to predict delays on the future data",
   "id": "427a408216d17e7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:22:11.007080Z",
     "start_time": "2024-05-18T11:22:10.902007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Ensure the FL_DATE column is a datetime object in df_future_data\n",
    "df_future_data_processed = df_future_data\n",
    "df_future_data_processed['FL_DATE'] = pd.to_datetime(df_future_data_processed['FL_DATE'])\n",
    "\n",
    "# Extract year, month, day, and dayofweek from FL_DATE\n",
    "df_future_data_processed['year'] = df_future_data_processed['FL_DATE'].dt.year\n",
    "df_future_data_processed['month'] = df_future_data_processed['FL_DATE'].dt.month\n",
    "df_future_data_processed['day'] = df_future_data_processed['FL_DATE'].dt.day\n",
    "df_future_data_processed['dayofweek'] = df_future_data_processed['FL_DATE'].dt.dayofweek\n",
    "\n",
    "# Convert DEP_TIME to datetime and extract hour and minute\n",
    "df_future_data_processed['DEP_TIME'] = pd.to_datetime(df_future_data_processed['DEP_TIME'], format='%H:%M:%S', errors='coerce')\n",
    "df_future_data_processed['DEP_HOUR'] = df_future_data_processed['DEP_TIME'].dt.hour\n",
    "df_future_data_processed['DEP_MINUTE'] = df_future_data_processed['DEP_TIME'].dt.minute\n",
    "\n",
    "# Ensure that DAY_OF_WEEK is included in df_future_data_processed\n",
    "df_future_data_processed['DAY_OF_WEEK'] = df_future_data_processed['FL_DATE'].dt.dayofweek + 1  # Assuming DAY_OF_WEEK starts from 1 for Monday\n",
    "\n",
    "# Define features for df_future_data_processed\n",
    "features = ['DAY_OF_WEEK', 'DEST_CITY_NAME', 'AIR_TIME', 'DEP_HOUR', 'DEP_MINUTE', 'PLANE_MODEL', \n",
    "            'temperature_2m', 'relative_humidity_2m', 'precipitation', 'pressure_msl', \n",
    "            'cloud_cover', 'wind_speed_10m', 'IS_HOLIDAY', 'year', 'month', 'day', 'dayofweek']\n",
    "\n",
    "X_future = df_future_data_processed[features]\n",
    "\n",
    "# Define the preprocessing for categorical features\n",
    "categorical_features = ['DEST_CITY_NAME', 'PLANE_MODEL']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Define the preprocessing for numeric features\n",
    "numeric_features = ['DAY_OF_WEEK', 'AIR_TIME', 'DEP_HOUR', 'DEP_MINUTE', 'temperature_2m', 'relative_humidity_2m', \n",
    "                    'precipitation', 'pressure_msl', 'cloud_cover', 'wind_speed_10m', \n",
    "                    'IS_HOLIDAY', 'year', 'month', 'day', 'dayofweek']\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the future data\n",
    "X_future_preprocessed = preprocessor.fit_transform(X_future)\n",
    "\n",
    "# Make predictions and get the confidence scores\n",
    "y_pred_future = best_rf_model.predict(X_future_preprocessed)\n",
    "y_pred_proba_future = best_rf_model.predict_proba(X_future_preprocessed)[:, 1]\n",
    "\n",
    "# Append the predictions and confidence scores to df_future_data_processed\n",
    "df_future_data_processed['PRED_DEL15'] = y_pred_future\n",
    "df_future_data_processed['CONF'] = y_pred_proba_future\n",
    "\n",
    "# Calculate the percentage of flights predicted to be delayed\n",
    "percentage_delayed = (df_future_data_processed['PRED_DEL15'].sum() / len(df_future_data_processed)) * 100\n",
    "\n",
    "# Print the updated df_future_data_processed and the percentage of predicted delays\n",
    "print(\"Updated df_future_data_processed:\")\n",
    "print(df_future_data_processed)\n",
    "\n",
    "print(f\"Percentage of flights predicted to be delayed: {percentage_delayed:.2f}%\")\n"
   ],
   "id": "155e357a729e1f41",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 52\u001B[0m\n\u001B[1;32m     49\u001B[0m X_future_preprocessed \u001B[38;5;241m=\u001B[39m preprocessor\u001B[38;5;241m.\u001B[39mfit_transform(X_future)\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# Make predictions and get the confidence scores\u001B[39;00m\n\u001B[0;32m---> 52\u001B[0m y_pred_future \u001B[38;5;241m=\u001B[39m \u001B[43mbest_rf_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_future_preprocessed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m y_pred_proba_future \u001B[38;5;241m=\u001B[39m best_rf_model\u001B[38;5;241m.\u001B[39mpredict_proba(X_future_preprocessed)[:, \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# Append the predictions and confidence scores to df_future_data_processed\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:905\u001B[0m, in \u001B[0;36mForestClassifier.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    884\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    885\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    886\u001B[0m \u001B[38;5;124;03m    Predict class for X.\u001B[39;00m\n\u001B[1;32m    887\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    903\u001B[0m \u001B[38;5;124;03m        The predicted classes.\u001B[39;00m\n\u001B[1;32m    904\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 905\u001B[0m     proba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    907\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    908\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\u001B[38;5;241m.\u001B[39mtake(np\u001B[38;5;241m.\u001B[39margmax(proba, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:947\u001B[0m, in \u001B[0;36mForestClassifier.predict_proba\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    945\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    946\u001B[0m \u001B[38;5;66;03m# Check data\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_X_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    949\u001B[0m \u001B[38;5;66;03m# Assign chunk of trees to jobs\u001B[39;00m\n\u001B[1;32m    950\u001B[0m n_jobs, _, _ \u001B[38;5;241m=\u001B[39m _partition_estimators(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_estimators, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:641\u001B[0m, in \u001B[0;36mBaseForest._validate_X_predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    639\u001B[0m     force_all_finite \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 641\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    642\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    643\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    644\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    645\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    646\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    647\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    648\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(X) \u001B[38;5;129;01mand\u001B[39;00m (X\u001B[38;5;241m.\u001B[39mindices\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc \u001B[38;5;129;01mor\u001B[39;00m X\u001B[38;5;241m.\u001B[39mindptr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc):\n\u001B[1;32m    649\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo support for np.int64 index based sparse matrices\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/base.py:633\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    631\u001B[0m         out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[0;32m--> 633\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[1;32m    635\u001B[0m     out \u001B[38;5;241m=\u001B[39m _check_y(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:963\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    961\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sp\u001B[38;5;241m.\u001B[39missparse(array):\n\u001B[1;32m    962\u001B[0m     _ensure_no_complex_data(array)\n\u001B[0;32m--> 963\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43m_ensure_sparse_format\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    964\u001B[0m \u001B[43m        \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    965\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    966\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    967\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    968\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    969\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    970\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    971\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001B[39;00m\n\u001B[1;32m    975\u001B[0m     \u001B[38;5;66;03m# to an error. This is needed because specifying a non complex\u001B[39;00m\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;66;03m# dtype to the function converts complex to real dtype,\u001B[39;00m\n\u001B[1;32m    977\u001B[0m     \u001B[38;5;66;03m# thereby passing the test made in the lines following the scope\u001B[39;00m\n\u001B[1;32m    978\u001B[0m     \u001B[38;5;66;03m# of warnings context manager.\u001B[39;00m\n\u001B[1;32m    979\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings():\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:631\u001B[0m, in \u001B[0;36m_ensure_sparse_format\u001B[0;34m(sparse_container, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    626\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    627\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt check \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msparse_container\u001B[38;5;241m.\u001B[39mformat\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m sparse matrix for nan or inf.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    628\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m    629\u001B[0m         )\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 631\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[43m            \u001B[49m\u001B[43msparse_container\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    633\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    634\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    635\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    636\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;66;03m# TODO: Remove when the minimum version of SciPy supported is 1.12\u001B[39;00m\n\u001B[1;32m    639\u001B[0m \u001B[38;5;66;03m# With SciPy sparse arrays, conversion from DIA format to COO, CSR, or BSR\u001B[39;00m\n\u001B[1;32m    640\u001B[0m \u001B[38;5;66;03m# triggers the use of `np.int64` indices even if the data is such that it could\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    643\u001B[0m \u001B[38;5;66;03m# algorithms support large indices, the following code downcasts to `np.int32`\u001B[39;00m\n\u001B[1;32m    644\u001B[0m \u001B[38;5;66;03m# indices when it's safe to do so.\u001B[39;00m\n\u001B[1;32m    645\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m changed_format:\n\u001B[1;32m    646\u001B[0m     \u001B[38;5;66;03m# accept_sparse is specified to a specific format and a conversion occurred\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:126\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m--> 126\u001B[0m \u001B[43m_assert_all_finite_element_wise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/pythonproject-_Wdx5WR7-py3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:175\u001B[0m, in \u001B[0;36m_assert_all_finite_element_wise\u001B[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    161\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    162\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    163\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    173\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    174\u001B[0m     )\n\u001B[0;32m--> 175\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[0;31mValueError\u001B[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_future_data[df_future_data.isna().any(axis=1)]",
   "id": "d4c8012aa81c1705",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
